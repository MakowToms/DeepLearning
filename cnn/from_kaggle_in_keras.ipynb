{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "from_kaggle_in_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AFDGGg5xYc5O",
        "XaDxgsvrAC8m",
        "GUJiuvKfLXU2",
        "SoOkN2eJLPjl",
        "mllUY8rjuB91",
        "PyqPJZFuOpjR",
        "IFaF8vyuLE5G",
        "b7mC0nVNMgqO",
        "PgdNN_12uIzH",
        "7McwJgikeZpy",
        "aHiZEOMvzcNt",
        "AxGHxuDJvfor"
      ],
      "mount_file_id": "1BxxRZ_nHxQAmlIP5EDx3HpLoQMfMPAEs",
      "authorship_tag": "ABX9TyOuExC+cv9cX77yu6tcNNP9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MakowToms/DeepLearning/blob/main/cnn/from_kaggle_in_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGrapZ2qY-YE"
      },
      "source": [
        "The CIFAR first steps. The following notebook is based on code from kaggle platform:\n",
        "https://www.kaggle.com/roblexnana/cifar10-with-cnn-for-beginer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFDGGg5xYc5O"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxmW8IIpYOnM",
        "outputId": "a4c04a80-3e93-4eb3-92d5-a398072de5f1"
      },
      "source": [
        "!pip install tensorflow-determinism\n",
        "!pip install natsort"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-determinism in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (5.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGDK67tZXTXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42427f82-d047-4943-daff-4a87c9943853"
      },
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # credits Wojciech Bogucki\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pandas as pd\n",
        "from natsort import natsorted\n",
        "import itertools\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 7635764407140200251\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14674281152\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 17091678831451319834\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Incx1Y69_Vbi"
      },
      "source": [
        "def set_seed(seed=123):\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "  \n",
        "set_seed()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0VKF1xiYjoW"
      },
      "source": [
        "# Set global variables\n",
        "batch_size = 32  # The default batch size of keras\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 100\n",
        "n = 5\n",
        "data_augmentation = False\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AazejXObY44o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f87c4c3-abb6-4114-d1fb-33d6e1b38638"
      },
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Normalize the data. Before we need to connvert data type to float for computation\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# Split train-validation dataset\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=123)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_val.shape[0], 'validation samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(y_val[:10].sum(axis=0) + y_test[:10].sum(axis=0) + y_train[:10].sum(axis=0))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "45000 train samples\n",
            "5000 validation samples\n",
            "10000 test samples\n",
            "[4. 6. 3. 2. 1. 1. 6. 2. 5. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaDxgsvrAC8m"
      },
      "source": [
        "## Define functions, optimizers and models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPiDq-JwuMg4"
      },
      "source": [
        "# Train exact model many times and get mean results\n",
        "\n",
        "def plotmodelhistory(history): \n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(history.history['accuracy']) \n",
        "    axs[0].plot(history.history['val_accuracy']) \n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy') \n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].legend(['train', 'validate'], loc='upper left')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(history.history['loss']) \n",
        "    axs[1].plot(history.history['val_loss']) \n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss') \n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].legend(['train', 'validate'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def results_of_model(model, opt, opt_name, n=10, plot=False, \n",
        "                     data_augmentation=False, \n",
        "                     shift=0.1, horizontal_flip=True, rotation=10, workers=4,\n",
        "                     early_stopping=early_stopping):\n",
        "    histories = []\n",
        "    for i in range(n):\n",
        "        print(f'\\n\\nModel {i}:')\n",
        "        set_seed(i+2)\n",
        "\n",
        "        model = tf.keras.models.clone_model(model)\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=opt,\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        if not data_augmentation:\n",
        "          history = model.fit(x_train, y_train,\n",
        "                              batch_size=batch_size,\n",
        "                              epochs=epochs,\n",
        "                              validation_data=(x_val, y_val),\n",
        "                              callbacks = [early_stopping],\n",
        "                              shuffle=True)\n",
        "        else:\n",
        "          datagen = ImageDataGenerator(\n",
        "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,  # apply ZCA whitening\n",
        "            zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "            rotation_range=rotation,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            # randomly shift images horizontally (fraction of total width)\n",
        "            width_shift_range=shift,\n",
        "            # randomly shift images vertically (fraction of total height)\n",
        "            height_shift_range=shift,\n",
        "            shear_range=0.,  # set range for random shear\n",
        "            zoom_range=0.,  # set range for random zoom\n",
        "            channel_shift_range=0.,  # set range for random channel shifts\n",
        "            # set mode for filling points outside the input boundaries\n",
        "            fill_mode='nearest',\n",
        "            cval=0.,  # value used for fill_mode = \"constant\"\n",
        "            horizontal_flip=horizontal_flip,  # randomly flip images\n",
        "            vertical_flip=False,  # randomly flip images\n",
        "            # set rescaling factor (applied before any other transformation)\n",
        "            rescale=None,\n",
        "            # set function that will be applied on each input\n",
        "            preprocessing_function=None,\n",
        "            # image data format, either \"channels_first\" or \"channels_last\"\n",
        "            data_format=None,\n",
        "            # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "            validation_split=0.0)\n",
        "\n",
        "          # Compute quantities required for feature-wise normalization\n",
        "          # (std, mean, and principal components if ZCA whitening is applied).\n",
        "          datagen.fit(x_train)\n",
        "\n",
        "          # Fit the model on the batches generated by datagen.flow().\n",
        "          history = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                        batch_size=batch_size),\n",
        "                                        epochs=epochs,\n",
        "                                        validation_data=(x_val, y_val),\n",
        "                                        callbacks = [early_stopping],\n",
        "                                        workers=workers)\n",
        "\n",
        "        histories.append((\n",
        "            history.history['accuracy'],\n",
        "            history.history['val_accuracy'],\n",
        "            history.history['loss'],\n",
        "            history.history['val_loss']\n",
        "        ))\n",
        "        if plot:\n",
        "            plotmodelhistory(history)\n",
        "\n",
        "    if not data_augmentation:\n",
        "      with open(f'drive/MyDrive/Colab Notebooks/pickles/{model.name}-{opt_name}', 'wb') as f:\n",
        "        pickle.dump(histories, f)\n",
        "    else:\n",
        "      with open(f'drive/MyDrive/Colab Notebooks/aug/{model.name}-{opt_name}-{shift}-{horizontal_flip}-{rotation}-{early_stopping.patience}', 'wb') as f:\n",
        "        pickle.dump(histories, f)\n",
        "\n",
        "\n",
        "    model = None\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    return histories"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPfTcTfgyXqe"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "set_seed(123)\n",
        "\n",
        "optimizers = [\n",
        "        (keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6), 'RMSProp'),\n",
        "        (keras.optimizers.Adam(learning_rate=0.001), 'Adam')\n",
        "]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej-JKANPv3iJ"
      },
      "source": [
        "# Train first models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc0vNhWct7Am"
      },
      "source": [
        "## 2 Conv Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUJiuvKfLXU2"
      },
      "source": [
        "### Basic 2 Conv Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5VKw2nNaJil",
        "outputId": "dcc43153-2085-405c-d42c-169b96ea96d9"
      },
      "source": [
        "set_seed(123)\n",
        "#define the model - convolution network\n",
        "model = Sequential(name='2ConvBlocks_smaller_padding')\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# FLATTERN => DENSE => RELU => DROPOUT\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# a softmax classifier\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers:\n",
        "    results_of_model(model, opt[0], opt[1], n=n)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"2ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 2.0614 - accuracy: 0.2299 - val_loss: 1.6010 - val_accuracy: 0.4238\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5858 - accuracy: 0.4281 - val_loss: 1.4363 - val_accuracy: 0.4874\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4214 - accuracy: 0.4881 - val_loss: 1.3680 - val_accuracy: 0.5160\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3234 - accuracy: 0.5253 - val_loss: 1.2908 - val_accuracy: 0.5518\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2419 - accuracy: 0.5566 - val_loss: 1.2903 - val_accuracy: 0.5482\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1777 - accuracy: 0.5779 - val_loss: 1.2826 - val_accuracy: 0.5592\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1157 - accuracy: 0.6031 - val_loss: 1.0497 - val_accuracy: 0.6342\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0653 - accuracy: 0.6262 - val_loss: 1.1067 - val_accuracy: 0.6170\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0303 - accuracy: 0.6392 - val_loss: 0.9995 - val_accuracy: 0.6486\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9899 - accuracy: 0.6530 - val_loss: 0.9429 - val_accuracy: 0.6680\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9479 - accuracy: 0.6685 - val_loss: 0.9500 - val_accuracy: 0.6688\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9111 - accuracy: 0.6791 - val_loss: 0.8985 - val_accuracy: 0.6930\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8917 - accuracy: 0.6844 - val_loss: 0.9376 - val_accuracy: 0.6790\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8594 - accuracy: 0.7005 - val_loss: 0.8852 - val_accuracy: 0.6942\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8477 - accuracy: 0.7016 - val_loss: 0.8603 - val_accuracy: 0.7024\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8272 - accuracy: 0.7124 - val_loss: 0.8009 - val_accuracy: 0.7294\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8060 - accuracy: 0.7156 - val_loss: 0.8112 - val_accuracy: 0.7252\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8070 - accuracy: 0.7207 - val_loss: 0.8208 - val_accuracy: 0.7202\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7852 - accuracy: 0.7245 - val_loss: 0.7908 - val_accuracy: 0.7298\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7658 - accuracy: 0.7390 - val_loss: 0.7799 - val_accuracy: 0.7344\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7576 - accuracy: 0.7369 - val_loss: 0.8120 - val_accuracy: 0.7260\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7496 - accuracy: 0.7422 - val_loss: 0.7945 - val_accuracy: 0.7298\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7478 - accuracy: 0.7396 - val_loss: 0.7922 - val_accuracy: 0.7294\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7289 - accuracy: 0.7478 - val_loss: 0.7512 - val_accuracy: 0.7390\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7246 - accuracy: 0.7496 - val_loss: 0.7843 - val_accuracy: 0.7326\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7253 - accuracy: 0.7519 - val_loss: 0.7623 - val_accuracy: 0.7468\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7203 - accuracy: 0.7524 - val_loss: 0.7659 - val_accuracy: 0.7440\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7161 - accuracy: 0.7540 - val_loss: 0.7558 - val_accuracy: 0.7500\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7073 - accuracy: 0.7582 - val_loss: 0.7820 - val_accuracy: 0.7388\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 2.0554 - accuracy: 0.2319 - val_loss: 1.5846 - val_accuracy: 0.4294\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5849 - accuracy: 0.4180 - val_loss: 1.5354 - val_accuracy: 0.4674\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4224 - accuracy: 0.4904 - val_loss: 1.3271 - val_accuracy: 0.5254\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3191 - accuracy: 0.5314 - val_loss: 1.2873 - val_accuracy: 0.5406\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2316 - accuracy: 0.5637 - val_loss: 1.2153 - val_accuracy: 0.5678\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1638 - accuracy: 0.5871 - val_loss: 1.1701 - val_accuracy: 0.5910\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1053 - accuracy: 0.6069 - val_loss: 1.1271 - val_accuracy: 0.6128\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0614 - accuracy: 0.6293 - val_loss: 1.0160 - val_accuracy: 0.6418\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0058 - accuracy: 0.6459 - val_loss: 0.9873 - val_accuracy: 0.6578\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9869 - accuracy: 0.6507 - val_loss: 0.9513 - val_accuracy: 0.6754\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9388 - accuracy: 0.6657 - val_loss: 0.9512 - val_accuracy: 0.6726\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9104 - accuracy: 0.6858 - val_loss: 0.9270 - val_accuracy: 0.6834\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8934 - accuracy: 0.6864 - val_loss: 0.8835 - val_accuracy: 0.6944\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8665 - accuracy: 0.6972 - val_loss: 0.8667 - val_accuracy: 0.6976\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8402 - accuracy: 0.7048 - val_loss: 0.8526 - val_accuracy: 0.7074\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8183 - accuracy: 0.7168 - val_loss: 0.8229 - val_accuracy: 0.7212\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8124 - accuracy: 0.7154 - val_loss: 0.8399 - val_accuracy: 0.7094\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7970 - accuracy: 0.7240 - val_loss: 0.8063 - val_accuracy: 0.7228\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8007 - accuracy: 0.7246 - val_loss: 0.7867 - val_accuracy: 0.7216\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7692 - accuracy: 0.7362 - val_loss: 0.8165 - val_accuracy: 0.7230\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7633 - accuracy: 0.7366 - val_loss: 0.7659 - val_accuracy: 0.7368\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7380 - accuracy: 0.7467 - val_loss: 0.7824 - val_accuracy: 0.7352\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7399 - accuracy: 0.7470 - val_loss: 0.7695 - val_accuracy: 0.7402\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7397 - accuracy: 0.7459 - val_loss: 0.7502 - val_accuracy: 0.7444\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7225 - accuracy: 0.7523 - val_loss: 0.7509 - val_accuracy: 0.7428\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7221 - accuracy: 0.7512 - val_loss: 0.7630 - val_accuracy: 0.7382\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7009 - accuracy: 0.7612 - val_loss: 0.7235 - val_accuracy: 0.7514\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6996 - accuracy: 0.7621 - val_loss: 0.7760 - val_accuracy: 0.7378\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7018 - accuracy: 0.7584 - val_loss: 0.7089 - val_accuracy: 0.7578\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7100 - accuracy: 0.7594 - val_loss: 0.7238 - val_accuracy: 0.7536\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6787 - accuracy: 0.7683 - val_loss: 0.7082 - val_accuracy: 0.7588\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6901 - accuracy: 0.7660 - val_loss: 0.7406 - val_accuracy: 0.7500\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6802 - accuracy: 0.7642 - val_loss: 0.6783 - val_accuracy: 0.7648\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6783 - accuracy: 0.7717 - val_loss: 0.7037 - val_accuracy: 0.7582\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6660 - accuracy: 0.7773 - val_loss: 0.6936 - val_accuracy: 0.7618\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6625 - accuracy: 0.7764 - val_loss: 0.6927 - val_accuracy: 0.7606\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6519 - accuracy: 0.7798 - val_loss: 0.6865 - val_accuracy: 0.7694\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6568 - accuracy: 0.7761 - val_loss: 0.6771 - val_accuracy: 0.7700\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6538 - accuracy: 0.7780 - val_loss: 0.7085 - val_accuracy: 0.7624\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6451 - accuracy: 0.7825 - val_loss: 0.6904 - val_accuracy: 0.7730\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6384 - accuracy: 0.7844 - val_loss: 0.6918 - val_accuracy: 0.7622\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6441 - accuracy: 0.7821 - val_loss: 0.7045 - val_accuracy: 0.7710\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6376 - accuracy: 0.7847 - val_loss: 0.6871 - val_accuracy: 0.7718\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 2.0429 - accuracy: 0.2373 - val_loss: 1.6777 - val_accuracy: 0.3810\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5855 - accuracy: 0.4233 - val_loss: 1.4761 - val_accuracy: 0.4644\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4158 - accuracy: 0.4904 - val_loss: 1.3282 - val_accuracy: 0.5318\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3277 - accuracy: 0.5247 - val_loss: 1.2525 - val_accuracy: 0.5560\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2454 - accuracy: 0.5610 - val_loss: 1.2113 - val_accuracy: 0.5712\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1931 - accuracy: 0.5758 - val_loss: 1.1348 - val_accuracy: 0.6034\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1337 - accuracy: 0.6016 - val_loss: 1.2022 - val_accuracy: 0.5760\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0839 - accuracy: 0.6193 - val_loss: 1.1362 - val_accuracy: 0.6126\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0450 - accuracy: 0.6307 - val_loss: 1.0093 - val_accuracy: 0.6428\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0051 - accuracy: 0.6484 - val_loss: 1.0522 - val_accuracy: 0.6330\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9769 - accuracy: 0.6559 - val_loss: 1.0023 - val_accuracy: 0.6594\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9372 - accuracy: 0.6708 - val_loss: 0.9981 - val_accuracy: 0.6596\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9153 - accuracy: 0.6798 - val_loss: 1.0126 - val_accuracy: 0.6522\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8933 - accuracy: 0.6899 - val_loss: 0.9928 - val_accuracy: 0.6576\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8688 - accuracy: 0.6961 - val_loss: 0.9635 - val_accuracy: 0.6706\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8606 - accuracy: 0.7005 - val_loss: 0.8615 - val_accuracy: 0.7056\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8299 - accuracy: 0.7116 - val_loss: 0.8681 - val_accuracy: 0.7034\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8271 - accuracy: 0.7135 - val_loss: 0.8266 - val_accuracy: 0.7192\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8066 - accuracy: 0.7226 - val_loss: 0.8659 - val_accuracy: 0.7030\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8025 - accuracy: 0.7229 - val_loss: 0.8354 - val_accuracy: 0.7132\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7860 - accuracy: 0.7299 - val_loss: 0.7995 - val_accuracy: 0.7300\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7706 - accuracy: 0.7317 - val_loss: 0.8227 - val_accuracy: 0.7208\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7681 - accuracy: 0.7337 - val_loss: 0.8493 - val_accuracy: 0.7142\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7568 - accuracy: 0.7368 - val_loss: 0.8076 - val_accuracy: 0.7220\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7432 - accuracy: 0.7420 - val_loss: 0.7803 - val_accuracy: 0.7396\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7389 - accuracy: 0.7482 - val_loss: 0.7723 - val_accuracy: 0.7366\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7283 - accuracy: 0.7500 - val_loss: 0.7510 - val_accuracy: 0.7478\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7279 - accuracy: 0.7504 - val_loss: 0.7847 - val_accuracy: 0.7372\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7239 - accuracy: 0.7511 - val_loss: 0.7657 - val_accuracy: 0.7430\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7277 - accuracy: 0.7535 - val_loss: 0.7855 - val_accuracy: 0.7320\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7103 - accuracy: 0.7528 - val_loss: 0.7363 - val_accuracy: 0.7520\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7065 - accuracy: 0.7609 - val_loss: 0.7243 - val_accuracy: 0.7570\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7037 - accuracy: 0.7647 - val_loss: 0.7501 - val_accuracy: 0.7448\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6930 - accuracy: 0.7650 - val_loss: 0.7414 - val_accuracy: 0.7524\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7032 - accuracy: 0.7636 - val_loss: 0.7327 - val_accuracy: 0.7544\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6870 - accuracy: 0.7659 - val_loss: 0.7227 - val_accuracy: 0.7532\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6894 - accuracy: 0.7647 - val_loss: 0.7270 - val_accuracy: 0.7588\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6826 - accuracy: 0.7679 - val_loss: 0.7407 - val_accuracy: 0.7526\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6740 - accuracy: 0.7687 - val_loss: 0.7721 - val_accuracy: 0.7404\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6757 - accuracy: 0.7745 - val_loss: 0.7104 - val_accuracy: 0.7626\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6777 - accuracy: 0.7746 - val_loss: 0.7057 - val_accuracy: 0.7566\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6678 - accuracy: 0.7744 - val_loss: 0.6951 - val_accuracy: 0.7612\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6613 - accuracy: 0.7757 - val_loss: 0.7242 - val_accuracy: 0.7510\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6572 - accuracy: 0.7761 - val_loss: 0.7364 - val_accuracy: 0.7610\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6750 - accuracy: 0.7693 - val_loss: 0.7790 - val_accuracy: 0.7428\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6496 - accuracy: 0.7794 - val_loss: 0.7061 - val_accuracy: 0.7562\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6575 - accuracy: 0.7759 - val_loss: 0.7820 - val_accuracy: 0.7506\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.0965 - accuracy: 0.2210 - val_loss: 1.6502 - val_accuracy: 0.4018\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6199 - accuracy: 0.4097 - val_loss: 1.5171 - val_accuracy: 0.4524\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4784 - accuracy: 0.4615 - val_loss: 1.3890 - val_accuracy: 0.5018\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3705 - accuracy: 0.5108 - val_loss: 1.3190 - val_accuracy: 0.5368\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2976 - accuracy: 0.5342 - val_loss: 1.2494 - val_accuracy: 0.5600\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2358 - accuracy: 0.5578 - val_loss: 1.1880 - val_accuracy: 0.5812\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1680 - accuracy: 0.5887 - val_loss: 1.1552 - val_accuracy: 0.5964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1208 - accuracy: 0.6018 - val_loss: 1.1273 - val_accuracy: 0.6126\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0766 - accuracy: 0.6183 - val_loss: 1.0736 - val_accuracy: 0.6278\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0481 - accuracy: 0.6322 - val_loss: 1.1126 - val_accuracy: 0.6152\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0174 - accuracy: 0.6424 - val_loss: 1.0243 - val_accuracy: 0.6394\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9822 - accuracy: 0.6551 - val_loss: 0.9531 - val_accuracy: 0.6624\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9635 - accuracy: 0.6629 - val_loss: 1.0496 - val_accuracy: 0.6342\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9442 - accuracy: 0.6724 - val_loss: 1.0105 - val_accuracy: 0.6548\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9056 - accuracy: 0.6860 - val_loss: 0.8868 - val_accuracy: 0.6972\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8853 - accuracy: 0.6912 - val_loss: 0.8878 - val_accuracy: 0.6958\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8810 - accuracy: 0.6897 - val_loss: 0.9055 - val_accuracy: 0.6918\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8625 - accuracy: 0.6990 - val_loss: 0.8934 - val_accuracy: 0.6942\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8456 - accuracy: 0.7054 - val_loss: 0.8581 - val_accuracy: 0.7046\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8273 - accuracy: 0.7144 - val_loss: 0.8426 - val_accuracy: 0.7138\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8189 - accuracy: 0.7181 - val_loss: 0.8377 - val_accuracy: 0.7198\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8153 - accuracy: 0.7193 - val_loss: 0.8129 - val_accuracy: 0.7202\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8004 - accuracy: 0.7242 - val_loss: 0.8125 - val_accuracy: 0.7236\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7888 - accuracy: 0.7286 - val_loss: 0.8244 - val_accuracy: 0.7186\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7899 - accuracy: 0.7261 - val_loss: 0.7997 - val_accuracy: 0.7258\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7725 - accuracy: 0.7370 - val_loss: 0.8414 - val_accuracy: 0.7198\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7651 - accuracy: 0.7391 - val_loss: 0.8218 - val_accuracy: 0.7192\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7692 - accuracy: 0.7352 - val_loss: 0.7792 - val_accuracy: 0.7310\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7597 - accuracy: 0.7392 - val_loss: 0.7534 - val_accuracy: 0.7384\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7476 - accuracy: 0.7447 - val_loss: 0.7620 - val_accuracy: 0.7416\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7439 - accuracy: 0.7469 - val_loss: 0.7715 - val_accuracy: 0.7380\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7348 - accuracy: 0.7504 - val_loss: 0.7682 - val_accuracy: 0.7368\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7349 - accuracy: 0.7479 - val_loss: 0.7516 - val_accuracy: 0.7438\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7319 - accuracy: 0.7510 - val_loss: 0.7493 - val_accuracy: 0.7454\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7178 - accuracy: 0.7554 - val_loss: 0.7648 - val_accuracy: 0.7478\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7179 - accuracy: 0.7588 - val_loss: 0.7379 - val_accuracy: 0.7506\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.7265 - accuracy: 0.7550 - val_loss: 0.7561 - val_accuracy: 0.7508\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7074 - accuracy: 0.7632 - val_loss: 0.7395 - val_accuracy: 0.7500\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6957 - accuracy: 0.7627 - val_loss: 0.7816 - val_accuracy: 0.7440\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7030 - accuracy: 0.7642 - val_loss: 0.9015 - val_accuracy: 0.7176\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6952 - accuracy: 0.7661 - val_loss: 0.7499 - val_accuracy: 0.7536\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.0510 - accuracy: 0.2374 - val_loss: 1.6361 - val_accuracy: 0.4158\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5973 - accuracy: 0.4179 - val_loss: 1.4666 - val_accuracy: 0.4720\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4457 - accuracy: 0.4727 - val_loss: 1.3678 - val_accuracy: 0.5188\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3463 - accuracy: 0.5202 - val_loss: 1.2978 - val_accuracy: 0.5342\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2618 - accuracy: 0.5509 - val_loss: 1.2933 - val_accuracy: 0.5588\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2099 - accuracy: 0.5730 - val_loss: 1.1874 - val_accuracy: 0.5844\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1588 - accuracy: 0.5900 - val_loss: 1.1682 - val_accuracy: 0.5946\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1126 - accuracy: 0.6115 - val_loss: 1.1796 - val_accuracy: 0.5944\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0608 - accuracy: 0.6273 - val_loss: 1.0277 - val_accuracy: 0.6376\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0312 - accuracy: 0.6387 - val_loss: 1.0038 - val_accuracy: 0.6466\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9966 - accuracy: 0.6496 - val_loss: 1.0695 - val_accuracy: 0.6382\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9659 - accuracy: 0.6614 - val_loss: 0.9568 - val_accuracy: 0.6644\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9395 - accuracy: 0.6723 - val_loss: 0.9482 - val_accuracy: 0.6708\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9205 - accuracy: 0.6762 - val_loss: 0.9295 - val_accuracy: 0.6706\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8975 - accuracy: 0.6862 - val_loss: 0.8848 - val_accuracy: 0.6902\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8727 - accuracy: 0.6945 - val_loss: 0.8822 - val_accuracy: 0.6956\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8528 - accuracy: 0.7042 - val_loss: 0.8774 - val_accuracy: 0.6952\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8409 - accuracy: 0.7063 - val_loss: 0.8441 - val_accuracy: 0.7098\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8353 - accuracy: 0.7126 - val_loss: 0.8571 - val_accuracy: 0.7030\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8230 - accuracy: 0.7162 - val_loss: 0.8983 - val_accuracy: 0.6912\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8050 - accuracy: 0.7217 - val_loss: 0.8416 - val_accuracy: 0.7134\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.7988 - accuracy: 0.7211 - val_loss: 0.8115 - val_accuracy: 0.7238\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7836 - accuracy: 0.7301 - val_loss: 0.7832 - val_accuracy: 0.7350\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7815 - accuracy: 0.7335 - val_loss: 0.8140 - val_accuracy: 0.7196\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7654 - accuracy: 0.7372 - val_loss: 0.7880 - val_accuracy: 0.7334\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7694 - accuracy: 0.7363 - val_loss: 0.7721 - val_accuracy: 0.7356\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7490 - accuracy: 0.7419 - val_loss: 0.7676 - val_accuracy: 0.7364\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7495 - accuracy: 0.7468 - val_loss: 0.7641 - val_accuracy: 0.7402\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7514 - accuracy: 0.7427 - val_loss: 0.7581 - val_accuracy: 0.7386\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7430 - accuracy: 0.7491 - val_loss: 0.7779 - val_accuracy: 0.7358\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7362 - accuracy: 0.7486 - val_loss: 0.7713 - val_accuracy: 0.7388\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7168 - accuracy: 0.7545 - val_loss: 0.7394 - val_accuracy: 0.7430\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7212 - accuracy: 0.7554 - val_loss: 0.7378 - val_accuracy: 0.7482\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7185 - accuracy: 0.7542 - val_loss: 0.7527 - val_accuracy: 0.7468\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7070 - accuracy: 0.7597 - val_loss: 0.7364 - val_accuracy: 0.7476\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7111 - accuracy: 0.7572 - val_loss: 0.7367 - val_accuracy: 0.7540\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6983 - accuracy: 0.7615 - val_loss: 0.7228 - val_accuracy: 0.7564\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7095 - accuracy: 0.7587 - val_loss: 0.7758 - val_accuracy: 0.7458\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6875 - accuracy: 0.7662 - val_loss: 0.7114 - val_accuracy: 0.7608\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6926 - accuracy: 0.7645 - val_loss: 0.7075 - val_accuracy: 0.7620\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6898 - accuracy: 0.7659 - val_loss: 0.7412 - val_accuracy: 0.7586\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6755 - accuracy: 0.7724 - val_loss: 0.7205 - val_accuracy: 0.7574\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6757 - accuracy: 0.7712 - val_loss: 0.6982 - val_accuracy: 0.7638\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.6763 - accuracy: 0.7740 - val_loss: 0.7094 - val_accuracy: 0.7616\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.6732 - accuracy: 0.7713 - val_loss: 0.7152 - val_accuracy: 0.7660\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.6829 - accuracy: 0.7685 - val_loss: 0.7156 - val_accuracy: 0.7622\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 0.6602 - accuracy: 0.7765 - val_loss: 0.6968 - val_accuracy: 0.7650\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.6538 - accuracy: 0.7792 - val_loss: 0.7072 - val_accuracy: 0.7570\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.6623 - accuracy: 0.7763 - val_loss: 0.7162 - val_accuracy: 0.7636\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.6519 - accuracy: 0.7761 - val_loss: 0.7101 - val_accuracy: 0.7596\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.6501 - accuracy: 0.7800 - val_loss: 0.7052 - val_accuracy: 0.7686\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.6478 - accuracy: 0.7833 - val_loss: 0.7032 - val_accuracy: 0.7708\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 1.8373 - accuracy: 0.3183 - val_loss: 1.3230 - val_accuracy: 0.5248\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2720 - accuracy: 0.5422 - val_loss: 1.0521 - val_accuracy: 0.6216\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0873 - accuracy: 0.6159 - val_loss: 0.9699 - val_accuracy: 0.6592\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9794 - accuracy: 0.6523 - val_loss: 1.0351 - val_accuracy: 0.6408\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9129 - accuracy: 0.6759 - val_loss: 0.9523 - val_accuracy: 0.6738\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8527 - accuracy: 0.6986 - val_loss: 0.8262 - val_accuracy: 0.7108\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8126 - accuracy: 0.7130 - val_loss: 0.8142 - val_accuracy: 0.7148\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7712 - accuracy: 0.7286 - val_loss: 0.7893 - val_accuracy: 0.7308\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7540 - accuracy: 0.7338 - val_loss: 0.7497 - val_accuracy: 0.7352\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7387 - accuracy: 0.7404 - val_loss: 0.8396 - val_accuracy: 0.7158\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7049 - accuracy: 0.7500 - val_loss: 0.7752 - val_accuracy: 0.7360\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6808 - accuracy: 0.7591 - val_loss: 0.7365 - val_accuracy: 0.7480\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6476 - accuracy: 0.7696 - val_loss: 0.8098 - val_accuracy: 0.7298\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6301 - accuracy: 0.7775 - val_loss: 0.7219 - val_accuracy: 0.7546\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6224 - accuracy: 0.7814 - val_loss: 0.7209 - val_accuracy: 0.7504\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6175 - accuracy: 0.7831 - val_loss: 0.7087 - val_accuracy: 0.7536\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.5927 - accuracy: 0.7906 - val_loss: 0.6967 - val_accuracy: 0.7580\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.6023 - accuracy: 0.7882 - val_loss: 0.7285 - val_accuracy: 0.7580\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.5793 - accuracy: 0.7965 - val_loss: 0.6788 - val_accuracy: 0.7668\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.5671 - accuracy: 0.8006 - val_loss: 0.6771 - val_accuracy: 0.7752\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.5451 - accuracy: 0.8075 - val_loss: 0.7587 - val_accuracy: 0.7524\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.5393 - accuracy: 0.8104 - val_loss: 0.6731 - val_accuracy: 0.7746\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 0.5281 - accuracy: 0.8156 - val_loss: 0.7052 - val_accuracy: 0.7616\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.5115 - accuracy: 0.8193 - val_loss: 0.7025 - val_accuracy: 0.7650\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 0.5171 - accuracy: 0.8183 - val_loss: 0.6814 - val_accuracy: 0.7730\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.5024 - accuracy: 0.8213 - val_loss: 0.6811 - val_accuracy: 0.7720\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.5067 - accuracy: 0.8214 - val_loss: 0.6962 - val_accuracy: 0.7662\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 2.3048 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 2.3028 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3028 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.0936\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 2.3028 - accuracy: 0.1021 - val_loss: 2.3031 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 16s 12ms/step - loss: 2.3026 - accuracy: 0.1005 - val_loss: 2.3028 - val_accuracy: 0.1050\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0936\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3033 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3029 - accuracy: 0.0962 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.0959 - val_loss: 2.3029 - val_accuracy: 0.0932\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.0363 - accuracy: 0.2354 - val_loss: 1.5616 - val_accuracy: 0.4362\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.5629 - accuracy: 0.4327 - val_loss: 1.3908 - val_accuracy: 0.4950\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4236 - accuracy: 0.4863 - val_loss: 1.3433 - val_accuracy: 0.5140\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3531 - accuracy: 0.5131 - val_loss: 1.2758 - val_accuracy: 0.5368\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2846 - accuracy: 0.5396 - val_loss: 1.2196 - val_accuracy: 0.5642\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2235 - accuracy: 0.5612 - val_loss: 1.1215 - val_accuracy: 0.6006\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1961 - accuracy: 0.5759 - val_loss: 1.1276 - val_accuracy: 0.5952\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1545 - accuracy: 0.5948 - val_loss: 1.0693 - val_accuracy: 0.6244\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1137 - accuracy: 0.6030 - val_loss: 1.0047 - val_accuracy: 0.6414\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0798 - accuracy: 0.6190 - val_loss: 1.0647 - val_accuracy: 0.6178\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0529 - accuracy: 0.6240 - val_loss: 0.9817 - val_accuracy: 0.6526\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0143 - accuracy: 0.6403 - val_loss: 0.9514 - val_accuracy: 0.6676\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0005 - accuracy: 0.6492 - val_loss: 0.9152 - val_accuracy: 0.6814\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9806 - accuracy: 0.6540 - val_loss: 0.8966 - val_accuracy: 0.6880\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9619 - accuracy: 0.6589 - val_loss: 0.9429 - val_accuracy: 0.6644\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9487 - accuracy: 0.6670 - val_loss: 0.8963 - val_accuracy: 0.6814\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9324 - accuracy: 0.6692 - val_loss: 0.9837 - val_accuracy: 0.6624\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.9171 - accuracy: 0.6753 - val_loss: 0.9008 - val_accuracy: 0.6878\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8955 - accuracy: 0.6825 - val_loss: 0.8970 - val_accuracy: 0.6858\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8966 - accuracy: 0.6846 - val_loss: 0.8251 - val_accuracy: 0.7112\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8644 - accuracy: 0.6911 - val_loss: 0.8252 - val_accuracy: 0.7180\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8571 - accuracy: 0.6945 - val_loss: 0.8237 - val_accuracy: 0.7194\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8511 - accuracy: 0.7024 - val_loss: 0.8044 - val_accuracy: 0.7188\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.8522 - accuracy: 0.6977 - val_loss: 0.8250 - val_accuracy: 0.7148\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8222 - accuracy: 0.7110 - val_loss: 0.8041 - val_accuracy: 0.7230\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8203 - accuracy: 0.7114 - val_loss: 0.8094 - val_accuracy: 0.7220\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8075 - accuracy: 0.7151 - val_loss: 0.7947 - val_accuracy: 0.7252\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7954 - accuracy: 0.7185 - val_loss: 0.8270 - val_accuracy: 0.7152\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.8040 - accuracy: 0.7175 - val_loss: 0.8170 - val_accuracy: 0.7204\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7831 - accuracy: 0.7247 - val_loss: 0.7830 - val_accuracy: 0.7294\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7782 - accuracy: 0.7253 - val_loss: 0.8954 - val_accuracy: 0.6974\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7644 - accuracy: 0.7284 - val_loss: 0.8360 - val_accuracy: 0.7144\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7615 - accuracy: 0.7310 - val_loss: 0.7759 - val_accuracy: 0.7316\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7540 - accuracy: 0.7346 - val_loss: 0.7901 - val_accuracy: 0.7334\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.7480 - accuracy: 0.7367 - val_loss: 0.7698 - val_accuracy: 0.7342\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7303 - accuracy: 0.7406 - val_loss: 0.7544 - val_accuracy: 0.7408\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7413 - accuracy: 0.7418 - val_loss: 0.7586 - val_accuracy: 0.7330\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7320 - accuracy: 0.7410 - val_loss: 0.7543 - val_accuracy: 0.7394\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7205 - accuracy: 0.7433 - val_loss: 0.8311 - val_accuracy: 0.7126\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 0.7213 - accuracy: 0.7427 - val_loss: 0.7388 - val_accuracy: 0.7430\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7126 - accuracy: 0.7485 - val_loss: 0.8109 - val_accuracy: 0.7244\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.7057 - accuracy: 0.7491 - val_loss: 0.7676 - val_accuracy: 0.7366\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6916 - accuracy: 0.7532 - val_loss: 0.8440 - val_accuracy: 0.7218\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6826 - accuracy: 0.7574 - val_loss: 0.7801 - val_accuracy: 0.7374\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 0.6971 - accuracy: 0.7525 - val_loss: 0.7478 - val_accuracy: 0.7494\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3057 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3030 - accuracy: 0.0976 - val_loss: 2.3033 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 17s 11ms/step - loss: 2.3057 - accuracy: 0.1004 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.1014 - val_loss: 2.3028 - val_accuracy: 0.1046\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3031 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3026 - accuracy: 0.1016 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3026 - accuracy: 0.0973 - val_loss: 2.3025 - val_accuracy: 0.1066\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 16s 11ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0956\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 15s 11ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.1066\n",
            "Ended optimizer Adam \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoOkN2eJLPjl"
      },
      "source": [
        "### 2 Conv Blocks without smaller padding (same padding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBY0mLzoHpCy",
        "outputId": "bbccdaac-977b-4cb2-b2e8-76c613d22023"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='2ConvBlocks_same_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers:\n",
        "    results_of_model(model, opt[0], opt[1], n=n)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"2ConvBlocks_same_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,168,362\n",
            "Trainable params: 2,168,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 57s 19ms/step - loss: 2.0273 - accuracy: 0.2519 - val_loss: 1.5703 - val_accuracy: 0.4346\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.5500 - accuracy: 0.4449 - val_loss: 1.3726 - val_accuracy: 0.5112\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.3607 - accuracy: 0.5141 - val_loss: 1.3140 - val_accuracy: 0.5278\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.2437 - accuracy: 0.5522 - val_loss: 1.2389 - val_accuracy: 0.5716\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 1.1525 - accuracy: 0.5899 - val_loss: 1.1505 - val_accuracy: 0.5970\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0855 - accuracy: 0.6183 - val_loss: 1.1571 - val_accuracy: 0.5912\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0221 - accuracy: 0.6400 - val_loss: 0.9707 - val_accuracy: 0.6652\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.9704 - accuracy: 0.6593 - val_loss: 0.9842 - val_accuracy: 0.6624\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.9364 - accuracy: 0.6713 - val_loss: 0.9291 - val_accuracy: 0.6794\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.9102 - accuracy: 0.6836 - val_loss: 0.8836 - val_accuracy: 0.6958\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8712 - accuracy: 0.6936 - val_loss: 0.8789 - val_accuracy: 0.6918\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8428 - accuracy: 0.7061 - val_loss: 0.8420 - val_accuracy: 0.7082\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8295 - accuracy: 0.7078 - val_loss: 0.8832 - val_accuracy: 0.6978\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8051 - accuracy: 0.7224 - val_loss: 0.8441 - val_accuracy: 0.7130\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7849 - accuracy: 0.7275 - val_loss: 0.8060 - val_accuracy: 0.7232\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7664 - accuracy: 0.7347 - val_loss: 0.7802 - val_accuracy: 0.7394\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7495 - accuracy: 0.7384 - val_loss: 0.8187 - val_accuracy: 0.7188\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7508 - accuracy: 0.7412 - val_loss: 0.7684 - val_accuracy: 0.7396\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7323 - accuracy: 0.7472 - val_loss: 0.7791 - val_accuracy: 0.7380\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7191 - accuracy: 0.7544 - val_loss: 0.7758 - val_accuracy: 0.7378\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7077 - accuracy: 0.7573 - val_loss: 0.7758 - val_accuracy: 0.7396\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7044 - accuracy: 0.7623 - val_loss: 0.7773 - val_accuracy: 0.7392\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6997 - accuracy: 0.7617 - val_loss: 0.7735 - val_accuracy: 0.7408\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 18ms/step - loss: 2.0338 - accuracy: 0.2474 - val_loss: 1.5469 - val_accuracy: 0.4508\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.5558 - accuracy: 0.4391 - val_loss: 1.5575 - val_accuracy: 0.4592\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.3853 - accuracy: 0.5050 - val_loss: 1.2970 - val_accuracy: 0.5426\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.2620 - accuracy: 0.5535 - val_loss: 1.2125 - val_accuracy: 0.5710\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1629 - accuracy: 0.5890 - val_loss: 1.1098 - val_accuracy: 0.6080\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0883 - accuracy: 0.6149 - val_loss: 1.0731 - val_accuracy: 0.6178\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0333 - accuracy: 0.6337 - val_loss: 0.9873 - val_accuracy: 0.6570\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9878 - accuracy: 0.6546 - val_loss: 0.9530 - val_accuracy: 0.6720\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9358 - accuracy: 0.6697 - val_loss: 0.9383 - val_accuracy: 0.6752\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9091 - accuracy: 0.6809 - val_loss: 0.8913 - val_accuracy: 0.6888\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8736 - accuracy: 0.6921 - val_loss: 0.9126 - val_accuracy: 0.6882\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8438 - accuracy: 0.7063 - val_loss: 0.8966 - val_accuracy: 0.6914\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8290 - accuracy: 0.7083 - val_loss: 0.8280 - val_accuracy: 0.7134\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8027 - accuracy: 0.7194 - val_loss: 0.8611 - val_accuracy: 0.7020\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7793 - accuracy: 0.7302 - val_loss: 0.8451 - val_accuracy: 0.7140\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7651 - accuracy: 0.7343 - val_loss: 0.8442 - val_accuracy: 0.7108\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7491 - accuracy: 0.7380 - val_loss: 0.7871 - val_accuracy: 0.7290\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7467 - accuracy: 0.7422 - val_loss: 0.7894 - val_accuracy: 0.7282\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7496 - accuracy: 0.7408 - val_loss: 0.7670 - val_accuracy: 0.7312\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7263 - accuracy: 0.7526 - val_loss: 0.8197 - val_accuracy: 0.7212\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7190 - accuracy: 0.7552 - val_loss: 0.7534 - val_accuracy: 0.7476\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6955 - accuracy: 0.7665 - val_loss: 0.7643 - val_accuracy: 0.7370\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6909 - accuracy: 0.7639 - val_loss: 0.7810 - val_accuracy: 0.7390\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6939 - accuracy: 0.7657 - val_loss: 0.8184 - val_accuracy: 0.7352\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6797 - accuracy: 0.7687 - val_loss: 0.7654 - val_accuracy: 0.7484\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6751 - accuracy: 0.7721 - val_loss: 0.7523 - val_accuracy: 0.7486\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6725 - accuracy: 0.7766 - val_loss: 0.7212 - val_accuracy: 0.7570\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6643 - accuracy: 0.7754 - val_loss: 0.7572 - val_accuracy: 0.7464\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6654 - accuracy: 0.7719 - val_loss: 0.7075 - val_accuracy: 0.7616\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6644 - accuracy: 0.7754 - val_loss: 0.7754 - val_accuracy: 0.7422\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6504 - accuracy: 0.7839 - val_loss: 0.7454 - val_accuracy: 0.7508\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6553 - accuracy: 0.7767 - val_loss: 0.7641 - val_accuracy: 0.7486\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6467 - accuracy: 0.7808 - val_loss: 0.6902 - val_accuracy: 0.7656\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6459 - accuracy: 0.7857 - val_loss: 0.7085 - val_accuracy: 0.7634\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6374 - accuracy: 0.7865 - val_loss: 0.7051 - val_accuracy: 0.7660\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6377 - accuracy: 0.7872 - val_loss: 0.8103 - val_accuracy: 0.7316\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6305 - accuracy: 0.7900 - val_loss: 0.7207 - val_accuracy: 0.7662\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6312 - accuracy: 0.7882 - val_loss: 0.7061 - val_accuracy: 0.7616\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 2.0134 - accuracy: 0.2565 - val_loss: 1.6411 - val_accuracy: 0.4010\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.5594 - accuracy: 0.4337 - val_loss: 1.4257 - val_accuracy: 0.4870\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.3797 - accuracy: 0.5038 - val_loss: 1.2905 - val_accuracy: 0.5358\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.2739 - accuracy: 0.5421 - val_loss: 1.1870 - val_accuracy: 0.5810\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1765 - accuracy: 0.5831 - val_loss: 1.2003 - val_accuracy: 0.5856\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1169 - accuracy: 0.6037 - val_loss: 1.0577 - val_accuracy: 0.6292\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0524 - accuracy: 0.6295 - val_loss: 1.1410 - val_accuracy: 0.5938\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0074 - accuracy: 0.6447 - val_loss: 1.0438 - val_accuracy: 0.6374\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9654 - accuracy: 0.6584 - val_loss: 0.9507 - val_accuracy: 0.6644\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9298 - accuracy: 0.6717 - val_loss: 0.9524 - val_accuracy: 0.6742\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8968 - accuracy: 0.6833 - val_loss: 0.9172 - val_accuracy: 0.6852\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8675 - accuracy: 0.6948 - val_loss: 0.9782 - val_accuracy: 0.6700\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8512 - accuracy: 0.7037 - val_loss: 0.9062 - val_accuracy: 0.6928\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8283 - accuracy: 0.7148 - val_loss: 0.9517 - val_accuracy: 0.6732\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8096 - accuracy: 0.7204 - val_loss: 0.8520 - val_accuracy: 0.7134\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8030 - accuracy: 0.7219 - val_loss: 0.8291 - val_accuracy: 0.7196\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7742 - accuracy: 0.7318 - val_loss: 0.8130 - val_accuracy: 0.7290\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7748 - accuracy: 0.7327 - val_loss: 0.7859 - val_accuracy: 0.7326\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7578 - accuracy: 0.7401 - val_loss: 0.8681 - val_accuracy: 0.7048\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7520 - accuracy: 0.7432 - val_loss: 0.8401 - val_accuracy: 0.7176\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7460 - accuracy: 0.7448 - val_loss: 0.7720 - val_accuracy: 0.7402\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7297 - accuracy: 0.7492 - val_loss: 0.7808 - val_accuracy: 0.7298\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7345 - accuracy: 0.7493 - val_loss: 0.7563 - val_accuracy: 0.7426\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7255 - accuracy: 0.7512 - val_loss: 0.7817 - val_accuracy: 0.7336\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7070 - accuracy: 0.7556 - val_loss: 0.7512 - val_accuracy: 0.7490\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7108 - accuracy: 0.7618 - val_loss: 0.7632 - val_accuracy: 0.7466\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7016 - accuracy: 0.7634 - val_loss: 0.7590 - val_accuracy: 0.7416\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7031 - accuracy: 0.7615 - val_loss: 0.7769 - val_accuracy: 0.7320\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7043 - accuracy: 0.7613 - val_loss: 0.7616 - val_accuracy: 0.7444\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7014 - accuracy: 0.7641 - val_loss: 0.7849 - val_accuracy: 0.7388\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 2.0564 - accuracy: 0.2400 - val_loss: 1.6473 - val_accuracy: 0.4066\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.5823 - accuracy: 0.4292 - val_loss: 1.4733 - val_accuracy: 0.4758\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.4312 - accuracy: 0.4873 - val_loss: 1.3539 - val_accuracy: 0.5212\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3097 - accuracy: 0.5327 - val_loss: 1.2370 - val_accuracy: 0.5608\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2319 - accuracy: 0.5610 - val_loss: 1.2285 - val_accuracy: 0.5622\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1697 - accuracy: 0.5853 - val_loss: 1.1491 - val_accuracy: 0.6044\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0972 - accuracy: 0.6125 - val_loss: 1.0775 - val_accuracy: 0.6284\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0513 - accuracy: 0.6300 - val_loss: 1.0468 - val_accuracy: 0.6402\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0087 - accuracy: 0.6449 - val_loss: 1.0023 - val_accuracy: 0.6562\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9787 - accuracy: 0.6599 - val_loss: 1.0747 - val_accuracy: 0.6298\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9449 - accuracy: 0.6703 - val_loss: 0.9527 - val_accuracy: 0.6722\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9110 - accuracy: 0.6817 - val_loss: 0.8954 - val_accuracy: 0.6910\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8903 - accuracy: 0.6905 - val_loss: 1.0398 - val_accuracy: 0.6422\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8730 - accuracy: 0.6940 - val_loss: 0.9348 - val_accuracy: 0.6810\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8348 - accuracy: 0.7114 - val_loss: 0.9056 - val_accuracy: 0.6876\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8200 - accuracy: 0.7186 - val_loss: 0.8484 - val_accuracy: 0.7012\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8095 - accuracy: 0.7173 - val_loss: 0.8323 - val_accuracy: 0.7170\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7881 - accuracy: 0.7310 - val_loss: 0.8627 - val_accuracy: 0.7090\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7804 - accuracy: 0.7317 - val_loss: 0.8308 - val_accuracy: 0.7202\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7633 - accuracy: 0.7404 - val_loss: 0.8395 - val_accuracy: 0.7140\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7523 - accuracy: 0.7418 - val_loss: 0.8013 - val_accuracy: 0.7252\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7439 - accuracy: 0.7479 - val_loss: 0.7914 - val_accuracy: 0.7294\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7296 - accuracy: 0.7525 - val_loss: 0.7800 - val_accuracy: 0.7376\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7327 - accuracy: 0.7515 - val_loss: 0.8218 - val_accuracy: 0.7374\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7272 - accuracy: 0.7538 - val_loss: 0.7504 - val_accuracy: 0.7496\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7084 - accuracy: 0.7603 - val_loss: 0.7652 - val_accuracy: 0.7430\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7034 - accuracy: 0.7624 - val_loss: 0.7921 - val_accuracy: 0.7330\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7061 - accuracy: 0.7618 - val_loss: 0.7684 - val_accuracy: 0.7452\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7043 - accuracy: 0.7639 - val_loss: 0.7391 - val_accuracy: 0.7538\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6957 - accuracy: 0.7680 - val_loss: 0.7621 - val_accuracy: 0.7474\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6893 - accuracy: 0.7679 - val_loss: 0.7406 - val_accuracy: 0.7572\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6869 - accuracy: 0.7725 - val_loss: 0.7597 - val_accuracy: 0.7488\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6873 - accuracy: 0.7704 - val_loss: 0.8651 - val_accuracy: 0.7210\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6773 - accuracy: 0.7726 - val_loss: 0.7463 - val_accuracy: 0.7554\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 28s 19ms/step - loss: 2.0271 - accuracy: 0.2463 - val_loss: 1.6044 - val_accuracy: 0.4332\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.5487 - accuracy: 0.4400 - val_loss: 1.4315 - val_accuracy: 0.4846\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3824 - accuracy: 0.4977 - val_loss: 1.2741 - val_accuracy: 0.5486\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.2748 - accuracy: 0.5458 - val_loss: 1.2569 - val_accuracy: 0.5432\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1811 - accuracy: 0.5823 - val_loss: 1.2039 - val_accuracy: 0.5856\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1211 - accuracy: 0.6055 - val_loss: 1.0723 - val_accuracy: 0.6254\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0683 - accuracy: 0.6216 - val_loss: 1.0099 - val_accuracy: 0.6490\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0170 - accuracy: 0.6450 - val_loss: 0.9981 - val_accuracy: 0.6514\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9689 - accuracy: 0.6617 - val_loss: 0.9921 - val_accuracy: 0.6606\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9421 - accuracy: 0.6716 - val_loss: 0.9256 - val_accuracy: 0.6814\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9056 - accuracy: 0.6825 - val_loss: 1.0112 - val_accuracy: 0.6586\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8858 - accuracy: 0.6915 - val_loss: 0.8906 - val_accuracy: 0.6894\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8546 - accuracy: 0.7020 - val_loss: 0.8899 - val_accuracy: 0.6904\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8356 - accuracy: 0.7081 - val_loss: 0.8560 - val_accuracy: 0.7064\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8240 - accuracy: 0.7125 - val_loss: 0.8412 - val_accuracy: 0.7102\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7966 - accuracy: 0.7213 - val_loss: 0.8010 - val_accuracy: 0.7304\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7828 - accuracy: 0.7273 - val_loss: 0.8207 - val_accuracy: 0.7150\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7679 - accuracy: 0.7357 - val_loss: 0.8028 - val_accuracy: 0.7250\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7569 - accuracy: 0.7349 - val_loss: 0.7939 - val_accuracy: 0.7252\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7531 - accuracy: 0.7419 - val_loss: 0.8055 - val_accuracy: 0.7180\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7419 - accuracy: 0.7440 - val_loss: 0.7880 - val_accuracy: 0.7292\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7290 - accuracy: 0.7481 - val_loss: 0.7749 - val_accuracy: 0.7402\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7230 - accuracy: 0.7525 - val_loss: 0.7371 - val_accuracy: 0.7468\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7236 - accuracy: 0.7559 - val_loss: 0.7846 - val_accuracy: 0.7320\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7108 - accuracy: 0.7556 - val_loss: 0.7722 - val_accuracy: 0.7352\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7073 - accuracy: 0.7563 - val_loss: 0.7493 - val_accuracy: 0.7440\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6997 - accuracy: 0.7614 - val_loss: 0.7222 - val_accuracy: 0.7532\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7007 - accuracy: 0.7641 - val_loss: 0.7287 - val_accuracy: 0.7546\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6999 - accuracy: 0.7639 - val_loss: 0.7364 - val_accuracy: 0.7538\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6816 - accuracy: 0.7705 - val_loss: 0.8069 - val_accuracy: 0.7262\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6821 - accuracy: 0.7681 - val_loss: 0.7866 - val_accuracy: 0.7384\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6696 - accuracy: 0.7725 - val_loss: 0.7563 - val_accuracy: 0.7440\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 1.8206 - accuracy: 0.3222 - val_loss: 1.2021 - val_accuracy: 0.5750\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 1.1816 - accuracy: 0.5771 - val_loss: 0.9675 - val_accuracy: 0.6564\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.9871 - accuracy: 0.6519 - val_loss: 0.8853 - val_accuracy: 0.6904\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.8853 - accuracy: 0.6875 - val_loss: 0.8314 - val_accuracy: 0.7118\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.8205 - accuracy: 0.7103 - val_loss: 0.7740 - val_accuracy: 0.7256\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.7647 - accuracy: 0.7314 - val_loss: 0.7942 - val_accuracy: 0.7232\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.7199 - accuracy: 0.7432 - val_loss: 0.7177 - val_accuracy: 0.7490\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.6735 - accuracy: 0.7638 - val_loss: 0.7345 - val_accuracy: 0.7438\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.6508 - accuracy: 0.7709 - val_loss: 0.7437 - val_accuracy: 0.7438\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.6212 - accuracy: 0.7804 - val_loss: 0.7960 - val_accuracy: 0.7282\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.5867 - accuracy: 0.7924 - val_loss: 0.7109 - val_accuracy: 0.7612\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.5618 - accuracy: 0.8011 - val_loss: 0.7217 - val_accuracy: 0.7482\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.5378 - accuracy: 0.8125 - val_loss: 0.7280 - val_accuracy: 0.7564\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.5183 - accuracy: 0.8167 - val_loss: 0.6736 - val_accuracy: 0.7648\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.4975 - accuracy: 0.8230 - val_loss: 0.7256 - val_accuracy: 0.7612\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.4878 - accuracy: 0.8276 - val_loss: 0.7149 - val_accuracy: 0.7598\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.4719 - accuracy: 0.8319 - val_loss: 0.6874 - val_accuracy: 0.7646\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.4517 - accuracy: 0.8397 - val_loss: 0.6845 - val_accuracy: 0.7718\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 0.4461 - accuracy: 0.8431 - val_loss: 0.6886 - val_accuracy: 0.7726\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 2.3042 - accuracy: 0.1022 - val_loss: 2.3032 - val_accuracy: 0.1066\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3031 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3031 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3027 - val_accuracy: 0.1046\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 2.3094 - accuracy: 0.0961 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3026 - accuracy: 0.1052 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1025 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.0956\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3217 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.1006\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3028 - accuracy: 0.0954 - val_loss: 2.3026 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 2.3066 - accuracy: 0.0995 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3029 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.1046\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 25s 17ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3031 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1004 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3026 - accuracy: 0.1016 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Ended optimizer Adam \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_b3_DtCK9vp"
      },
      "source": [
        "## 3 Conv Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mllUY8rjuB91"
      },
      "source": [
        "### 3 Conv Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKXtJvZSsL4a",
        "outputId": "092ca79c-4fa6-46cc-a2b2-b5c80bbe39d3"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='3ConvBlocks_same_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers:\n",
        "    results_of_model(model, opt[0], opt[1], n=n)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"3ConvBlocks_same_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,341,226\n",
            "Trainable params: 1,341,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 2.1077 - accuracy: 0.2059 - val_loss: 1.6489 - val_accuracy: 0.4056\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.6445 - accuracy: 0.4042 - val_loss: 1.4397 - val_accuracy: 0.4756\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.4451 - accuracy: 0.4763 - val_loss: 1.5582 - val_accuracy: 0.4516\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.3253 - accuracy: 0.5210 - val_loss: 1.2839 - val_accuracy: 0.5454\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.2177 - accuracy: 0.5659 - val_loss: 1.1223 - val_accuracy: 0.6006\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.1319 - accuracy: 0.5943 - val_loss: 1.2609 - val_accuracy: 0.5646\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0487 - accuracy: 0.6271 - val_loss: 1.0158 - val_accuracy: 0.6370\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.9930 - accuracy: 0.6490 - val_loss: 1.0206 - val_accuracy: 0.6466\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9437 - accuracy: 0.6652 - val_loss: 0.9262 - val_accuracy: 0.6716\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9097 - accuracy: 0.6773 - val_loss: 0.8458 - val_accuracy: 0.7038\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.8620 - accuracy: 0.6980 - val_loss: 0.8709 - val_accuracy: 0.6942\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.8289 - accuracy: 0.7077 - val_loss: 0.8239 - val_accuracy: 0.7118\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.8079 - accuracy: 0.7167 - val_loss: 0.7880 - val_accuracy: 0.7274\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.7784 - accuracy: 0.7249 - val_loss: 0.8246 - val_accuracy: 0.7110\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.7558 - accuracy: 0.7346 - val_loss: 0.8276 - val_accuracy: 0.7130\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.7322 - accuracy: 0.7431 - val_loss: 0.7386 - val_accuracy: 0.7432\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7105 - accuracy: 0.7502 - val_loss: 0.7583 - val_accuracy: 0.7350\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.7003 - accuracy: 0.7573 - val_loss: 0.6934 - val_accuracy: 0.7588\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.6694 - accuracy: 0.7681 - val_loss: 0.6869 - val_accuracy: 0.7614\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.6557 - accuracy: 0.7714 - val_loss: 0.6915 - val_accuracy: 0.7634\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.6467 - accuracy: 0.7736 - val_loss: 0.6699 - val_accuracy: 0.7620\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.6409 - accuracy: 0.7793 - val_loss: 0.6802 - val_accuracy: 0.7662\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6214 - accuracy: 0.7837 - val_loss: 0.7092 - val_accuracy: 0.7574\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.6063 - accuracy: 0.7897 - val_loss: 0.6405 - val_accuracy: 0.7798\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5940 - accuracy: 0.7934 - val_loss: 0.6611 - val_accuracy: 0.7742\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5996 - accuracy: 0.7954 - val_loss: 0.6826 - val_accuracy: 0.7664\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5948 - accuracy: 0.7930 - val_loss: 0.6800 - val_accuracy: 0.7668\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5777 - accuracy: 0.7999 - val_loss: 0.6121 - val_accuracy: 0.7898\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5700 - accuracy: 0.8056 - val_loss: 0.6326 - val_accuracy: 0.7888\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.5578 - accuracy: 0.8102 - val_loss: 0.6412 - val_accuracy: 0.7832\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5544 - accuracy: 0.8100 - val_loss: 0.6417 - val_accuracy: 0.7838\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5450 - accuracy: 0.8114 - val_loss: 0.6189 - val_accuracy: 0.7916\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5352 - accuracy: 0.8178 - val_loss: 0.6060 - val_accuracy: 0.8008\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5388 - accuracy: 0.8158 - val_loss: 0.6757 - val_accuracy: 0.7812\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5243 - accuracy: 0.8195 - val_loss: 0.5763 - val_accuracy: 0.8094\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5269 - accuracy: 0.8229 - val_loss: 0.6387 - val_accuracy: 0.7818\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5184 - accuracy: 0.8230 - val_loss: 0.5864 - val_accuracy: 0.8016\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5138 - accuracy: 0.8267 - val_loss: 0.6918 - val_accuracy: 0.7816\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5102 - accuracy: 0.8268 - val_loss: 0.6134 - val_accuracy: 0.7908\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5064 - accuracy: 0.8257 - val_loss: 0.6921 - val_accuracy: 0.7812\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 2.0940 - accuracy: 0.2101 - val_loss: 1.6920 - val_accuracy: 0.3768\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.6484 - accuracy: 0.3930 - val_loss: 1.5196 - val_accuracy: 0.4580\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.4756 - accuracy: 0.4611 - val_loss: 1.3648 - val_accuracy: 0.5026\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.3354 - accuracy: 0.5155 - val_loss: 1.3140 - val_accuracy: 0.5308\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.2305 - accuracy: 0.5582 - val_loss: 1.2725 - val_accuracy: 0.5484\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.1433 - accuracy: 0.5945 - val_loss: 1.1391 - val_accuracy: 0.5896\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0721 - accuracy: 0.6199 - val_loss: 1.0087 - val_accuracy: 0.6496\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0165 - accuracy: 0.6382 - val_loss: 0.9522 - val_accuracy: 0.6650\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9593 - accuracy: 0.6613 - val_loss: 0.9724 - val_accuracy: 0.6610\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9249 - accuracy: 0.6768 - val_loss: 0.9101 - val_accuracy: 0.6850\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.8825 - accuracy: 0.6916 - val_loss: 0.8895 - val_accuracy: 0.6920\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.8338 - accuracy: 0.7098 - val_loss: 0.8186 - val_accuracy: 0.7150\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.8108 - accuracy: 0.7170 - val_loss: 0.7957 - val_accuracy: 0.7252\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.7824 - accuracy: 0.7263 - val_loss: 0.7625 - val_accuracy: 0.7358\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.7600 - accuracy: 0.7335 - val_loss: 0.7510 - val_accuracy: 0.7408\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.7298 - accuracy: 0.7487 - val_loss: 0.7564 - val_accuracy: 0.7410\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.7147 - accuracy: 0.7498 - val_loss: 0.7297 - val_accuracy: 0.7500\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.6951 - accuracy: 0.7563 - val_loss: 0.7173 - val_accuracy: 0.7496\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.6876 - accuracy: 0.7584 - val_loss: 0.6713 - val_accuracy: 0.7656\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.6603 - accuracy: 0.7715 - val_loss: 0.7170 - val_accuracy: 0.7612\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.6506 - accuracy: 0.7745 - val_loss: 0.6905 - val_accuracy: 0.7646\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.6275 - accuracy: 0.7814 - val_loss: 0.6838 - val_accuracy: 0.7628\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.6123 - accuracy: 0.7873 - val_loss: 0.7158 - val_accuracy: 0.7610\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.6098 - accuracy: 0.7893 - val_loss: 0.6519 - val_accuracy: 0.7842\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.5887 - accuracy: 0.7958 - val_loss: 0.6488 - val_accuracy: 0.7782\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5842 - accuracy: 0.8007 - val_loss: 0.7158 - val_accuracy: 0.7574\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.5737 - accuracy: 0.8067 - val_loss: 0.6059 - val_accuracy: 0.7920\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5640 - accuracy: 0.8057 - val_loss: 0.7721 - val_accuracy: 0.7474\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5629 - accuracy: 0.8082 - val_loss: 0.6821 - val_accuracy: 0.7666\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5633 - accuracy: 0.8069 - val_loss: 0.6170 - val_accuracy: 0.7870\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5465 - accuracy: 0.8124 - val_loss: 0.6165 - val_accuracy: 0.7872\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.5356 - accuracy: 0.8154 - val_loss: 0.6144 - val_accuracy: 0.7890\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 2.0606 - accuracy: 0.2249 - val_loss: 1.7442 - val_accuracy: 0.3584\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.6417 - accuracy: 0.3985 - val_loss: 1.4892 - val_accuracy: 0.4604\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.4656 - accuracy: 0.4695 - val_loss: 1.3522 - val_accuracy: 0.5140\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3454 - accuracy: 0.5112 - val_loss: 1.2463 - val_accuracy: 0.5492\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.2417 - accuracy: 0.5545 - val_loss: 1.1609 - val_accuracy: 0.5816\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.1694 - accuracy: 0.5822 - val_loss: 1.1021 - val_accuracy: 0.6088\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 1.0962 - accuracy: 0.6112 - val_loss: 1.1135 - val_accuracy: 0.5984\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0384 - accuracy: 0.6315 - val_loss: 1.1586 - val_accuracy: 0.6058\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9837 - accuracy: 0.6542 - val_loss: 0.9667 - val_accuracy: 0.6596\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9446 - accuracy: 0.6651 - val_loss: 0.9461 - val_accuracy: 0.6682\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 0.9017 - accuracy: 0.6822 - val_loss: 0.9260 - val_accuracy: 0.6778\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8646 - accuracy: 0.6978 - val_loss: 0.8382 - val_accuracy: 0.7024\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8361 - accuracy: 0.7056 - val_loss: 0.9025 - val_accuracy: 0.6854\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8093 - accuracy: 0.7175 - val_loss: 0.8666 - val_accuracy: 0.6986\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7828 - accuracy: 0.7239 - val_loss: 0.8301 - val_accuracy: 0.7180\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7706 - accuracy: 0.7302 - val_loss: 0.7897 - val_accuracy: 0.7238\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7377 - accuracy: 0.7417 - val_loss: 0.7768 - val_accuracy: 0.7282\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7249 - accuracy: 0.7487 - val_loss: 0.7141 - val_accuracy: 0.7528\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6956 - accuracy: 0.7571 - val_loss: 0.7984 - val_accuracy: 0.7278\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6940 - accuracy: 0.7618 - val_loss: 0.7100 - val_accuracy: 0.7506\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6755 - accuracy: 0.7653 - val_loss: 0.6688 - val_accuracy: 0.7674\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6615 - accuracy: 0.7708 - val_loss: 0.6869 - val_accuracy: 0.7632\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6562 - accuracy: 0.7724 - val_loss: 0.6829 - val_accuracy: 0.7656\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6394 - accuracy: 0.7774 - val_loss: 0.6472 - val_accuracy: 0.7754\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6107 - accuracy: 0.7896 - val_loss: 0.6836 - val_accuracy: 0.7614\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6096 - accuracy: 0.7881 - val_loss: 0.6688 - val_accuracy: 0.7728\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5984 - accuracy: 0.7939 - val_loss: 0.6771 - val_accuracy: 0.7698\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5987 - accuracy: 0.7909 - val_loss: 0.6864 - val_accuracy: 0.7690\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5909 - accuracy: 0.7959 - val_loss: 0.6260 - val_accuracy: 0.7870\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5742 - accuracy: 0.7996 - val_loss: 0.6640 - val_accuracy: 0.7746\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5734 - accuracy: 0.8003 - val_loss: 0.6704 - val_accuracy: 0.7714\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5631 - accuracy: 0.8053 - val_loss: 0.6281 - val_accuracy: 0.7806\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5612 - accuracy: 0.8078 - val_loss: 0.6367 - val_accuracy: 0.7810\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5452 - accuracy: 0.8125 - val_loss: 0.5904 - val_accuracy: 0.7948\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5465 - accuracy: 0.8153 - val_loss: 0.6677 - val_accuracy: 0.7776\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5395 - accuracy: 0.8166 - val_loss: 0.5985 - val_accuracy: 0.7932\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5327 - accuracy: 0.8154 - val_loss: 0.6225 - val_accuracy: 0.7904\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5223 - accuracy: 0.8234 - val_loss: 0.6571 - val_accuracy: 0.7812\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5180 - accuracy: 0.8204 - val_loss: 0.5585 - val_accuracy: 0.8084\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5195 - accuracy: 0.8215 - val_loss: 0.5600 - val_accuracy: 0.8120\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5093 - accuracy: 0.8275 - val_loss: 0.6068 - val_accuracy: 0.7930\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5104 - accuracy: 0.8281 - val_loss: 0.6304 - val_accuracy: 0.7904\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5019 - accuracy: 0.8295 - val_loss: 0.5898 - val_accuracy: 0.7998\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5057 - accuracy: 0.8291 - val_loss: 0.6445 - val_accuracy: 0.7924\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 2.1207 - accuracy: 0.2041 - val_loss: 1.6757 - val_accuracy: 0.3780\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.6682 - accuracy: 0.3866 - val_loss: 1.5984 - val_accuracy: 0.4214\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.5121 - accuracy: 0.4502 - val_loss: 1.4188 - val_accuracy: 0.4844\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.3862 - accuracy: 0.4978 - val_loss: 1.2871 - val_accuracy: 0.5348\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.2938 - accuracy: 0.5343 - val_loss: 1.2996 - val_accuracy: 0.5348\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.2158 - accuracy: 0.5625 - val_loss: 1.2026 - val_accuracy: 0.5702\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.1330 - accuracy: 0.5964 - val_loss: 1.0988 - val_accuracy: 0.6136\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0744 - accuracy: 0.6182 - val_loss: 1.0257 - val_accuracy: 0.6408\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0315 - accuracy: 0.6334 - val_loss: 0.9800 - val_accuracy: 0.6536\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9875 - accuracy: 0.6500 - val_loss: 1.1131 - val_accuracy: 0.6222\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9456 - accuracy: 0.6699 - val_loss: 0.9994 - val_accuracy: 0.6454\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9092 - accuracy: 0.6801 - val_loss: 0.8665 - val_accuracy: 0.6922\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8805 - accuracy: 0.6901 - val_loss: 1.0284 - val_accuracy: 0.6482\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8546 - accuracy: 0.6996 - val_loss: 0.8646 - val_accuracy: 0.6926\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8222 - accuracy: 0.7119 - val_loss: 0.8873 - val_accuracy: 0.6912\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7953 - accuracy: 0.7239 - val_loss: 0.8209 - val_accuracy: 0.7158\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7784 - accuracy: 0.7280 - val_loss: 0.7749 - val_accuracy: 0.7332\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7527 - accuracy: 0.7357 - val_loss: 0.7865 - val_accuracy: 0.7238\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7347 - accuracy: 0.7455 - val_loss: 0.7744 - val_accuracy: 0.7414\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7175 - accuracy: 0.7477 - val_loss: 0.7875 - val_accuracy: 0.7290\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6998 - accuracy: 0.7603 - val_loss: 0.7684 - val_accuracy: 0.7342\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6846 - accuracy: 0.7609 - val_loss: 0.7206 - val_accuracy: 0.7508\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6684 - accuracy: 0.7693 - val_loss: 0.7954 - val_accuracy: 0.7352\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6591 - accuracy: 0.7699 - val_loss: 0.6803 - val_accuracy: 0.7630\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6535 - accuracy: 0.7733 - val_loss: 0.6687 - val_accuracy: 0.7690\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6279 - accuracy: 0.7846 - val_loss: 0.6491 - val_accuracy: 0.7754\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6216 - accuracy: 0.7878 - val_loss: 0.6311 - val_accuracy: 0.7836\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6151 - accuracy: 0.7875 - val_loss: 0.6822 - val_accuracy: 0.7734\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6005 - accuracy: 0.7920 - val_loss: 0.6592 - val_accuracy: 0.7740\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5963 - accuracy: 0.7930 - val_loss: 0.6156 - val_accuracy: 0.7910\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5903 - accuracy: 0.7980 - val_loss: 0.6865 - val_accuracy: 0.7770\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5741 - accuracy: 0.8021 - val_loss: 0.7338 - val_accuracy: 0.7622\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5739 - accuracy: 0.8015 - val_loss: 0.7192 - val_accuracy: 0.7686\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5637 - accuracy: 0.8073 - val_loss: 0.5948 - val_accuracy: 0.8006\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5495 - accuracy: 0.8119 - val_loss: 0.5973 - val_accuracy: 0.7986\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5481 - accuracy: 0.8138 - val_loss: 0.6173 - val_accuracy: 0.7996\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 0.5463 - accuracy: 0.8132 - val_loss: 0.6414 - val_accuracy: 0.7834\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5351 - accuracy: 0.8160 - val_loss: 0.5913 - val_accuracy: 0.8010\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5272 - accuracy: 0.8195 - val_loss: 0.6615 - val_accuracy: 0.7856\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5272 - accuracy: 0.8215 - val_loss: 0.6134 - val_accuracy: 0.7990\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5255 - accuracy: 0.8193 - val_loss: 0.6729 - val_accuracy: 0.7810\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5158 - accuracy: 0.8216 - val_loss: 0.6999 - val_accuracy: 0.7752\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5159 - accuracy: 0.8257 - val_loss: 0.6179 - val_accuracy: 0.7984\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 33s 23ms/step - loss: 2.0956 - accuracy: 0.2056 - val_loss: 1.6931 - val_accuracy: 0.3902\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.6241 - accuracy: 0.4037 - val_loss: 1.4840 - val_accuracy: 0.4626\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 1.4507 - accuracy: 0.4705 - val_loss: 1.3194 - val_accuracy: 0.5330\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 32s 22ms/step - loss: 1.3358 - accuracy: 0.5180 - val_loss: 1.3339 - val_accuracy: 0.5186\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.2332 - accuracy: 0.5564 - val_loss: 1.2296 - val_accuracy: 0.5710\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.1660 - accuracy: 0.5835 - val_loss: 1.1458 - val_accuracy: 0.5990\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0945 - accuracy: 0.6131 - val_loss: 1.0241 - val_accuracy: 0.6464\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.0413 - accuracy: 0.6341 - val_loss: 0.9514 - val_accuracy: 0.6626\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9820 - accuracy: 0.6507 - val_loss: 0.9922 - val_accuracy: 0.6594\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9504 - accuracy: 0.6712 - val_loss: 0.9036 - val_accuracy: 0.6878\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.9105 - accuracy: 0.6797 - val_loss: 0.9860 - val_accuracy: 0.6706\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8779 - accuracy: 0.6902 - val_loss: 0.8601 - val_accuracy: 0.6994\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8450 - accuracy: 0.7051 - val_loss: 0.9064 - val_accuracy: 0.6854\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.8259 - accuracy: 0.7111 - val_loss: 0.8154 - val_accuracy: 0.7162\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7979 - accuracy: 0.7207 - val_loss: 0.7537 - val_accuracy: 0.7364\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7732 - accuracy: 0.7282 - val_loss: 0.7791 - val_accuracy: 0.7280\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7491 - accuracy: 0.7368 - val_loss: 0.7787 - val_accuracy: 0.7326\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7350 - accuracy: 0.7426 - val_loss: 0.7705 - val_accuracy: 0.7318\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7180 - accuracy: 0.7479 - val_loss: 0.7775 - val_accuracy: 0.7272\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.7068 - accuracy: 0.7553 - val_loss: 0.7159 - val_accuracy: 0.7496\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6858 - accuracy: 0.7626 - val_loss: 0.7263 - val_accuracy: 0.7526\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6735 - accuracy: 0.7674 - val_loss: 0.7700 - val_accuracy: 0.7298\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6583 - accuracy: 0.7702 - val_loss: 0.6481 - val_accuracy: 0.7806\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6502 - accuracy: 0.7755 - val_loss: 0.7196 - val_accuracy: 0.7580\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6325 - accuracy: 0.7810 - val_loss: 0.6484 - val_accuracy: 0.7766\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6304 - accuracy: 0.7836 - val_loss: 0.6454 - val_accuracy: 0.7762\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6167 - accuracy: 0.7872 - val_loss: 0.6935 - val_accuracy: 0.7668\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6127 - accuracy: 0.7891 - val_loss: 0.6049 - val_accuracy: 0.7916\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.6021 - accuracy: 0.7922 - val_loss: 0.6610 - val_accuracy: 0.7716\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5862 - accuracy: 0.7971 - val_loss: 0.6355 - val_accuracy: 0.7798\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5728 - accuracy: 0.7991 - val_loss: 0.6435 - val_accuracy: 0.7836\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5617 - accuracy: 0.8057 - val_loss: 0.6661 - val_accuracy: 0.7780\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5607 - accuracy: 0.8061 - val_loss: 0.5791 - val_accuracy: 0.7984\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5594 - accuracy: 0.8063 - val_loss: 0.6429 - val_accuracy: 0.7808\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5489 - accuracy: 0.8138 - val_loss: 0.6185 - val_accuracy: 0.7890\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5539 - accuracy: 0.8130 - val_loss: 0.6342 - val_accuracy: 0.7850\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5295 - accuracy: 0.8165 - val_loss: 0.5716 - val_accuracy: 0.8072\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5387 - accuracy: 0.8156 - val_loss: 0.6293 - val_accuracy: 0.7922\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5234 - accuracy: 0.8188 - val_loss: 0.5910 - val_accuracy: 0.8010\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5130 - accuracy: 0.8234 - val_loss: 0.5664 - val_accuracy: 0.8098\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5080 - accuracy: 0.8242 - val_loss: 0.5997 - val_accuracy: 0.7960\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5035 - accuracy: 0.8263 - val_loss: 0.5944 - val_accuracy: 0.8002\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5031 - accuracy: 0.8313 - val_loss: 0.6032 - val_accuracy: 0.7956\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.5031 - accuracy: 0.8269 - val_loss: 0.5884 - val_accuracy: 0.7994\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 0.4914 - accuracy: 0.8308 - val_loss: 0.6077 - val_accuracy: 0.7946\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 1.9623 - accuracy: 0.2618 - val_loss: 1.4593 - val_accuracy: 0.4600\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.3305 - accuracy: 0.5170 - val_loss: 1.0663 - val_accuracy: 0.6158\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 1.0908 - accuracy: 0.6107 - val_loss: 1.0132 - val_accuracy: 0.6418\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.9944 - accuracy: 0.6480 - val_loss: 0.9038 - val_accuracy: 0.6902\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.9217 - accuracy: 0.6741 - val_loss: 0.8154 - val_accuracy: 0.7150\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.8597 - accuracy: 0.6964 - val_loss: 0.7986 - val_accuracy: 0.7122\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.8375 - accuracy: 0.7031 - val_loss: 0.7842 - val_accuracy: 0.7212\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.7940 - accuracy: 0.7178 - val_loss: 0.7651 - val_accuracy: 0.7374\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.7611 - accuracy: 0.7304 - val_loss: 0.7539 - val_accuracy: 0.7358\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.7404 - accuracy: 0.7401 - val_loss: 0.7575 - val_accuracy: 0.7324\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.7147 - accuracy: 0.7505 - val_loss: 0.7211 - val_accuracy: 0.7500\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 0.7162 - accuracy: 0.7502 - val_loss: 0.7415 - val_accuracy: 0.7548\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6900 - accuracy: 0.7558 - val_loss: 0.7231 - val_accuracy: 0.7524\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6754 - accuracy: 0.7637 - val_loss: 0.7238 - val_accuracy: 0.7486\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6842 - accuracy: 0.7611 - val_loss: 0.6824 - val_accuracy: 0.7712\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6558 - accuracy: 0.7710 - val_loss: 0.6576 - val_accuracy: 0.7718\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6567 - accuracy: 0.7708 - val_loss: 0.6775 - val_accuracy: 0.7664\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6416 - accuracy: 0.7789 - val_loss: 0.6806 - val_accuracy: 0.7682\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6428 - accuracy: 0.7752 - val_loss: 0.6901 - val_accuracy: 0.7640\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6401 - accuracy: 0.7764 - val_loss: 0.6789 - val_accuracy: 0.7704\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 0.6286 - accuracy: 0.7847 - val_loss: 0.6760 - val_accuracy: 0.7684\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 31s 21ms/step - loss: 2.3057 - accuracy: 0.1015 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3029 - accuracy: 0.1004 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3033 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3029 - accuracy: 0.0962 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0959 - val_loss: 2.3029 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 31s 21ms/step - loss: 2.3049 - accuracy: 0.0978 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3029 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.1014\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3028 - accuracy: 0.0960 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1025 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.0956\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 31s 21ms/step - loss: 2.3042 - accuracy: 0.0995 - val_loss: 2.3028 - val_accuracy: 0.1006\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3029 - accuracy: 0.0975 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3028 - accuracy: 0.0940 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 29s 21ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 31s 21ms/step - loss: 2.3110 - accuracy: 0.1013 - val_loss: 2.3031 - val_accuracy: 0.0932\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3030 - accuracy: 0.0969 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.1046\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 30s 22ms/step - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3028 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3031 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3026 - accuracy: 0.1016 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3026 - accuracy: 0.0973 - val_loss: 2.3025 - val_accuracy: 0.1066\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0956\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 30s 21ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.1066\n",
            "Ended optimizer Adam \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyqPJZFuOpjR"
      },
      "source": [
        "### 3 Conv Blocks with smaller padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKrhu637OpjS",
        "outputId": "fb87e116-cbf2-455b-d996-e9f5c9a2912e"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='3ConvBlocks_smaller_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers:\n",
        "    results_of_model(model, opt[0], opt[1], n=n)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 554,794\n",
            "Trainable params: 554,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 28s 19ms/step - loss: 2.1602 - accuracy: 0.1752 - val_loss: 1.7576 - val_accuracy: 0.3460\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.7372 - accuracy: 0.3624 - val_loss: 1.5529 - val_accuracy: 0.4212\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.5462 - accuracy: 0.4318 - val_loss: 1.8386 - val_accuracy: 0.3672\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.4322 - accuracy: 0.4772 - val_loss: 1.3695 - val_accuracy: 0.5140\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3341 - accuracy: 0.5181 - val_loss: 1.3408 - val_accuracy: 0.5218\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.2513 - accuracy: 0.5486 - val_loss: 1.3388 - val_accuracy: 0.5298\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1823 - accuracy: 0.5795 - val_loss: 1.1244 - val_accuracy: 0.5958\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1164 - accuracy: 0.6036 - val_loss: 1.1439 - val_accuracy: 0.6066\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0597 - accuracy: 0.6243 - val_loss: 1.0350 - val_accuracy: 0.6344\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0201 - accuracy: 0.6412 - val_loss: 0.9957 - val_accuracy: 0.6446\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9671 - accuracy: 0.6590 - val_loss: 0.9986 - val_accuracy: 0.6510\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9275 - accuracy: 0.6752 - val_loss: 0.9142 - val_accuracy: 0.6854\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8973 - accuracy: 0.6860 - val_loss: 0.9015 - val_accuracy: 0.6880\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8599 - accuracy: 0.7011 - val_loss: 0.8379 - val_accuracy: 0.6980\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8406 - accuracy: 0.7064 - val_loss: 0.8549 - val_accuracy: 0.6972\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8024 - accuracy: 0.7194 - val_loss: 0.7956 - val_accuracy: 0.7226\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7799 - accuracy: 0.7229 - val_loss: 0.7503 - val_accuracy: 0.7344\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7625 - accuracy: 0.7340 - val_loss: 0.7752 - val_accuracy: 0.7214\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7332 - accuracy: 0.7405 - val_loss: 0.7533 - val_accuracy: 0.7394\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.7120 - accuracy: 0.7534 - val_loss: 0.7229 - val_accuracy: 0.7492\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6979 - accuracy: 0.7583 - val_loss: 0.7223 - val_accuracy: 0.7508\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6873 - accuracy: 0.7660 - val_loss: 0.6784 - val_accuracy: 0.7628\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6751 - accuracy: 0.7650 - val_loss: 0.7376 - val_accuracy: 0.7474\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6546 - accuracy: 0.7704 - val_loss: 0.7253 - val_accuracy: 0.7482\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6426 - accuracy: 0.7794 - val_loss: 0.6898 - val_accuracy: 0.7618\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6395 - accuracy: 0.7779 - val_loss: 0.6492 - val_accuracy: 0.7830\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6305 - accuracy: 0.7818 - val_loss: 0.7121 - val_accuracy: 0.7560\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6170 - accuracy: 0.7851 - val_loss: 0.6745 - val_accuracy: 0.7706\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5998 - accuracy: 0.7934 - val_loss: 0.6679 - val_accuracy: 0.7790\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5983 - accuracy: 0.7927 - val_loss: 0.6755 - val_accuracy: 0.7680\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5867 - accuracy: 0.7966 - val_loss: 0.6330 - val_accuracy: 0.7848\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5758 - accuracy: 0.8007 - val_loss: 0.6672 - val_accuracy: 0.7798\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5628 - accuracy: 0.8059 - val_loss: 0.6592 - val_accuracy: 0.7764\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5654 - accuracy: 0.8053 - val_loss: 0.6273 - val_accuracy: 0.7848\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5512 - accuracy: 0.8084 - val_loss: 0.6287 - val_accuracy: 0.7886\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5519 - accuracy: 0.8100 - val_loss: 0.6347 - val_accuracy: 0.7838\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5420 - accuracy: 0.8135 - val_loss: 0.6544 - val_accuracy: 0.7814\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5425 - accuracy: 0.8153 - val_loss: 0.6280 - val_accuracy: 0.7866\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5307 - accuracy: 0.8166 - val_loss: 0.6178 - val_accuracy: 0.7918\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5279 - accuracy: 0.8183 - val_loss: 0.6175 - val_accuracy: 0.7918\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5239 - accuracy: 0.8189 - val_loss: 0.7395 - val_accuracy: 0.7566\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5222 - accuracy: 0.8206 - val_loss: 0.6538 - val_accuracy: 0.7904\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5116 - accuracy: 0.8279 - val_loss: 0.6039 - val_accuracy: 0.7950\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5048 - accuracy: 0.8241 - val_loss: 0.6127 - val_accuracy: 0.7980\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.5103 - accuracy: 0.8293 - val_loss: 0.6535 - val_accuracy: 0.7850\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.4998 - accuracy: 0.8285 - val_loss: 0.6484 - val_accuracy: 0.7912\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.4979 - accuracy: 0.8256 - val_loss: 0.6373 - val_accuracy: 0.7930\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.4959 - accuracy: 0.8300 - val_loss: 0.6239 - val_accuracy: 0.7930\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 28s 19ms/step - loss: 2.1545 - accuracy: 0.1757 - val_loss: 1.8035 - val_accuracy: 0.3290\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7438 - accuracy: 0.3470 - val_loss: 1.5768 - val_accuracy: 0.4266\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.5485 - accuracy: 0.4287 - val_loss: 1.5332 - val_accuracy: 0.4492\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.4326 - accuracy: 0.4779 - val_loss: 1.4054 - val_accuracy: 0.4974\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.3373 - accuracy: 0.5167 - val_loss: 1.3322 - val_accuracy: 0.5198\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2559 - accuracy: 0.5497 - val_loss: 1.2238 - val_accuracy: 0.5574\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1864 - accuracy: 0.5758 - val_loss: 1.1293 - val_accuracy: 0.5992\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.1279 - accuracy: 0.6024 - val_loss: 1.0588 - val_accuracy: 0.6164\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0681 - accuracy: 0.6216 - val_loss: 1.0822 - val_accuracy: 0.6204\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 1.0400 - accuracy: 0.6321 - val_loss: 1.0238 - val_accuracy: 0.6404\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9883 - accuracy: 0.6493 - val_loss: 1.0038 - val_accuracy: 0.6494\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.9487 - accuracy: 0.6656 - val_loss: 0.9493 - val_accuracy: 0.6612\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9339 - accuracy: 0.6692 - val_loss: 0.8861 - val_accuracy: 0.6810\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8890 - accuracy: 0.6866 - val_loss: 0.8559 - val_accuracy: 0.6970\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8653 - accuracy: 0.6954 - val_loss: 0.8279 - val_accuracy: 0.7078\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8317 - accuracy: 0.7075 - val_loss: 0.8046 - val_accuracy: 0.7140\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.8181 - accuracy: 0.7142 - val_loss: 0.7981 - val_accuracy: 0.7212\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7948 - accuracy: 0.7204 - val_loss: 0.8880 - val_accuracy: 0.6932\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7859 - accuracy: 0.7260 - val_loss: 0.7699 - val_accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7493 - accuracy: 0.7376 - val_loss: 0.7794 - val_accuracy: 0.7328\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7354 - accuracy: 0.7443 - val_loss: 0.8020 - val_accuracy: 0.7274\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7061 - accuracy: 0.7502 - val_loss: 0.7262 - val_accuracy: 0.7488\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6859 - accuracy: 0.7633 - val_loss: 0.7561 - val_accuracy: 0.7432\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6867 - accuracy: 0.7592 - val_loss: 0.6978 - val_accuracy: 0.7652\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6600 - accuracy: 0.7692 - val_loss: 0.6753 - val_accuracy: 0.7626\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6454 - accuracy: 0.7782 - val_loss: 0.7286 - val_accuracy: 0.7558\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6338 - accuracy: 0.7837 - val_loss: 0.6690 - val_accuracy: 0.7710\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6161 - accuracy: 0.7848 - val_loss: 0.6717 - val_accuracy: 0.7678\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6248 - accuracy: 0.7825 - val_loss: 0.6380 - val_accuracy: 0.7766\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6047 - accuracy: 0.7913 - val_loss: 0.6398 - val_accuracy: 0.7692\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5918 - accuracy: 0.7923 - val_loss: 0.6387 - val_accuracy: 0.7780\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5867 - accuracy: 0.7953 - val_loss: 0.6511 - val_accuracy: 0.7762\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5788 - accuracy: 0.8012 - val_loss: 0.6462 - val_accuracy: 0.7774\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5631 - accuracy: 0.8056 - val_loss: 0.6359 - val_accuracy: 0.7764\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5550 - accuracy: 0.8076 - val_loss: 0.6022 - val_accuracy: 0.7940\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5542 - accuracy: 0.8090 - val_loss: 0.6316 - val_accuracy: 0.7832\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5426 - accuracy: 0.8101 - val_loss: 0.6411 - val_accuracy: 0.7828\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5429 - accuracy: 0.8123 - val_loss: 0.6024 - val_accuracy: 0.7950\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5360 - accuracy: 0.8149 - val_loss: 0.6329 - val_accuracy: 0.7844\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5188 - accuracy: 0.8198 - val_loss: 0.6333 - val_accuracy: 0.7884\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 28s 19ms/step - loss: 2.1276 - accuracy: 0.1891 - val_loss: 1.8089 - val_accuracy: 0.3170\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7326 - accuracy: 0.3558 - val_loss: 1.5893 - val_accuracy: 0.4128\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5446 - accuracy: 0.4326 - val_loss: 1.4561 - val_accuracy: 0.4648\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4424 - accuracy: 0.4714 - val_loss: 1.4141 - val_accuracy: 0.4918\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3567 - accuracy: 0.5081 - val_loss: 1.2888 - val_accuracy: 0.5348\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2794 - accuracy: 0.5386 - val_loss: 1.1872 - val_accuracy: 0.5760\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2178 - accuracy: 0.5634 - val_loss: 1.2253 - val_accuracy: 0.5508\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1553 - accuracy: 0.5873 - val_loss: 1.1423 - val_accuracy: 0.6048\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0998 - accuracy: 0.6064 - val_loss: 1.0286 - val_accuracy: 0.6380\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0570 - accuracy: 0.6222 - val_loss: 1.1084 - val_accuracy: 0.6092\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0235 - accuracy: 0.6355 - val_loss: 0.9569 - val_accuracy: 0.6606\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9717 - accuracy: 0.6547 - val_loss: 1.0491 - val_accuracy: 0.6388\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9402 - accuracy: 0.6672 - val_loss: 1.0187 - val_accuracy: 0.6484\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9091 - accuracy: 0.6801 - val_loss: 1.0713 - val_accuracy: 0.6328\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8862 - accuracy: 0.6871 - val_loss: 0.9843 - val_accuracy: 0.6630\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8611 - accuracy: 0.6976 - val_loss: 0.8418 - val_accuracy: 0.7144\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8256 - accuracy: 0.7105 - val_loss: 0.8152 - val_accuracy: 0.7154\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8110 - accuracy: 0.7199 - val_loss: 0.7622 - val_accuracy: 0.7324\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7792 - accuracy: 0.7280 - val_loss: 0.8438 - val_accuracy: 0.7048\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7695 - accuracy: 0.7338 - val_loss: 0.7683 - val_accuracy: 0.7350\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7439 - accuracy: 0.7428 - val_loss: 0.7292 - val_accuracy: 0.7464\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7284 - accuracy: 0.7510 - val_loss: 0.7588 - val_accuracy: 0.7446\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7189 - accuracy: 0.7528 - val_loss: 0.7287 - val_accuracy: 0.7556\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7001 - accuracy: 0.7572 - val_loss: 0.7353 - val_accuracy: 0.7502\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6654 - accuracy: 0.7674 - val_loss: 0.6775 - val_accuracy: 0.7668\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6680 - accuracy: 0.7659 - val_loss: 0.6934 - val_accuracy: 0.7632\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6612 - accuracy: 0.7721 - val_loss: 0.6823 - val_accuracy: 0.7708\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6481 - accuracy: 0.7764 - val_loss: 0.7154 - val_accuracy: 0.7602\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6392 - accuracy: 0.7770 - val_loss: 0.6907 - val_accuracy: 0.7704\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6260 - accuracy: 0.7855 - val_loss: 0.7656 - val_accuracy: 0.7444\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 28s 19ms/step - loss: 2.1695 - accuracy: 0.1724 - val_loss: 1.7939 - val_accuracy: 0.3370\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7609 - accuracy: 0.3413 - val_loss: 1.6330 - val_accuracy: 0.3986\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5869 - accuracy: 0.4146 - val_loss: 1.4777 - val_accuracy: 0.4598\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4612 - accuracy: 0.4645 - val_loss: 1.3493 - val_accuracy: 0.5126\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3708 - accuracy: 0.4981 - val_loss: 1.3859 - val_accuracy: 0.5098\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2973 - accuracy: 0.5336 - val_loss: 1.3100 - val_accuracy: 0.5342\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2207 - accuracy: 0.5619 - val_loss: 1.2469 - val_accuracy: 0.5608\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1573 - accuracy: 0.5859 - val_loss: 1.0832 - val_accuracy: 0.6106\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1185 - accuracy: 0.6026 - val_loss: 1.0488 - val_accuracy: 0.6282\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0734 - accuracy: 0.6162 - val_loss: 1.1897 - val_accuracy: 0.5936\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0365 - accuracy: 0.6300 - val_loss: 1.0408 - val_accuracy: 0.6298\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9893 - accuracy: 0.6497 - val_loss: 0.9566 - val_accuracy: 0.6602\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9681 - accuracy: 0.6577 - val_loss: 1.0502 - val_accuracy: 0.6338\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9465 - accuracy: 0.6653 - val_loss: 0.9406 - val_accuracy: 0.6644\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9124 - accuracy: 0.6804 - val_loss: 0.9133 - val_accuracy: 0.6834\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8819 - accuracy: 0.6871 - val_loss: 0.8951 - val_accuracy: 0.6850\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8709 - accuracy: 0.6890 - val_loss: 0.8727 - val_accuracy: 0.6988\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8346 - accuracy: 0.7070 - val_loss: 0.8441 - val_accuracy: 0.7084\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8213 - accuracy: 0.7129 - val_loss: 0.8100 - val_accuracy: 0.7204\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7931 - accuracy: 0.7193 - val_loss: 0.8337 - val_accuracy: 0.7086\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7747 - accuracy: 0.7297 - val_loss: 0.7836 - val_accuracy: 0.7282\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7595 - accuracy: 0.7327 - val_loss: 0.7761 - val_accuracy: 0.7322\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7398 - accuracy: 0.7418 - val_loss: 0.7358 - val_accuracy: 0.7448\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7307 - accuracy: 0.7434 - val_loss: 0.7150 - val_accuracy: 0.7516\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7212 - accuracy: 0.7499 - val_loss: 0.7059 - val_accuracy: 0.7594\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6884 - accuracy: 0.7608 - val_loss: 0.7353 - val_accuracy: 0.7466\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6815 - accuracy: 0.7645 - val_loss: 0.7591 - val_accuracy: 0.7372\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 27s 20ms/step - loss: 0.6704 - accuracy: 0.7681 - val_loss: 0.6956 - val_accuracy: 0.7654\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6584 - accuracy: 0.7737 - val_loss: 0.6895 - val_accuracy: 0.7648\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6416 - accuracy: 0.7749 - val_loss: 0.6825 - val_accuracy: 0.7678\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6294 - accuracy: 0.7811 - val_loss: 0.6690 - val_accuracy: 0.7710\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6188 - accuracy: 0.7869 - val_loss: 0.7211 - val_accuracy: 0.7522\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6185 - accuracy: 0.7876 - val_loss: 0.6690 - val_accuracy: 0.7774\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6128 - accuracy: 0.7894 - val_loss: 0.6376 - val_accuracy: 0.7898\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5899 - accuracy: 0.7954 - val_loss: 0.6803 - val_accuracy: 0.7700\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5832 - accuracy: 0.7988 - val_loss: 0.6338 - val_accuracy: 0.7836\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5977 - accuracy: 0.7960 - val_loss: 0.6558 - val_accuracy: 0.7778\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5610 - accuracy: 0.8079 - val_loss: 0.6355 - val_accuracy: 0.7836\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5631 - accuracy: 0.8048 - val_loss: 0.6519 - val_accuracy: 0.7890\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5583 - accuracy: 0.8088 - val_loss: 0.7423 - val_accuracy: 0.7650\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 27s 20ms/step - loss: 0.5652 - accuracy: 0.8046 - val_loss: 0.7469 - val_accuracy: 0.7558\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 29s 19ms/step - loss: 2.1443 - accuracy: 0.1800 - val_loss: 1.8404 - val_accuracy: 0.3456\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.7207 - accuracy: 0.3544 - val_loss: 1.5753 - val_accuracy: 0.4256\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.5453 - accuracy: 0.4280 - val_loss: 1.4457 - val_accuracy: 0.4782\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.4318 - accuracy: 0.4772 - val_loss: 1.3896 - val_accuracy: 0.4984\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.3451 - accuracy: 0.5139 - val_loss: 1.3553 - val_accuracy: 0.5244\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 28s 20ms/step - loss: 1.2800 - accuracy: 0.5374 - val_loss: 1.2508 - val_accuracy: 0.5498\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.2190 - accuracy: 0.5654 - val_loss: 1.1562 - val_accuracy: 0.5868\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1585 - accuracy: 0.5870 - val_loss: 1.0931 - val_accuracy: 0.6080\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.1045 - accuracy: 0.6064 - val_loss: 1.0652 - val_accuracy: 0.6254\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0731 - accuracy: 0.6201 - val_loss: 1.0495 - val_accuracy: 0.6336\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 1.0200 - accuracy: 0.6388 - val_loss: 0.9779 - val_accuracy: 0.6598\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 28s 20ms/step - loss: 0.9901 - accuracy: 0.6519 - val_loss: 0.9712 - val_accuracy: 0.6652\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9536 - accuracy: 0.6648 - val_loss: 0.9251 - val_accuracy: 0.6714\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.9312 - accuracy: 0.6697 - val_loss: 0.8703 - val_accuracy: 0.6924\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8981 - accuracy: 0.6846 - val_loss: 0.8447 - val_accuracy: 0.7044\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8761 - accuracy: 0.6924 - val_loss: 0.8548 - val_accuracy: 0.7102\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8487 - accuracy: 0.7032 - val_loss: 0.8553 - val_accuracy: 0.7102\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8323 - accuracy: 0.7094 - val_loss: 0.8097 - val_accuracy: 0.7168\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.8139 - accuracy: 0.7170 - val_loss: 0.8504 - val_accuracy: 0.6978\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7933 - accuracy: 0.7196 - val_loss: 0.8829 - val_accuracy: 0.6976\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7616 - accuracy: 0.7358 - val_loss: 0.7956 - val_accuracy: 0.7258\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7548 - accuracy: 0.7383 - val_loss: 0.7702 - val_accuracy: 0.7378\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7334 - accuracy: 0.7438 - val_loss: 0.7097 - val_accuracy: 0.7548\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7244 - accuracy: 0.7464 - val_loss: 0.7192 - val_accuracy: 0.7528\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.7022 - accuracy: 0.7541 - val_loss: 0.7193 - val_accuracy: 0.7510\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6968 - accuracy: 0.7564 - val_loss: 0.7452 - val_accuracy: 0.7468\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6821 - accuracy: 0.7638 - val_loss: 0.7083 - val_accuracy: 0.7544\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6716 - accuracy: 0.7706 - val_loss: 0.6567 - val_accuracy: 0.7738\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6639 - accuracy: 0.7700 - val_loss: 0.6890 - val_accuracy: 0.7650\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6392 - accuracy: 0.7794 - val_loss: 0.6739 - val_accuracy: 0.7696\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6377 - accuracy: 0.7781 - val_loss: 0.7434 - val_accuracy: 0.7518\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 27s 20ms/step - loss: 0.6165 - accuracy: 0.7870 - val_loss: 0.6469 - val_accuracy: 0.7832\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6085 - accuracy: 0.7852 - val_loss: 0.6524 - val_accuracy: 0.7820\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.6061 - accuracy: 0.7894 - val_loss: 0.6633 - val_accuracy: 0.7774\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5927 - accuracy: 0.7943 - val_loss: 0.6787 - val_accuracy: 0.7674\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5878 - accuracy: 0.7964 - val_loss: 0.6632 - val_accuracy: 0.7862\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5720 - accuracy: 0.8056 - val_loss: 0.6028 - val_accuracy: 0.8012\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 27s 20ms/step - loss: 0.5713 - accuracy: 0.8035 - val_loss: 0.6185 - val_accuracy: 0.7852\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5677 - accuracy: 0.8022 - val_loss: 0.6076 - val_accuracy: 0.7982\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5582 - accuracy: 0.8056 - val_loss: 0.6185 - val_accuracy: 0.7976\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5459 - accuracy: 0.8105 - val_loss: 0.6076 - val_accuracy: 0.7980\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 0.5372 - accuracy: 0.8131 - val_loss: 0.6526 - val_accuracy: 0.7812\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 18ms/step - loss: 2.1947 - accuracy: 0.1458 - val_loss: 1.6516 - val_accuracy: 0.3812\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.5475 - accuracy: 0.4277 - val_loss: 1.3364 - val_accuracy: 0.5146\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.3404 - accuracy: 0.5148 - val_loss: 1.1995 - val_accuracy: 0.5718\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.2307 - accuracy: 0.5568 - val_loss: 1.1214 - val_accuracy: 0.6070\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.1521 - accuracy: 0.5903 - val_loss: 1.0618 - val_accuracy: 0.6262\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0881 - accuracy: 0.6137 - val_loss: 0.9860 - val_accuracy: 0.6504\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 1.0411 - accuracy: 0.6318 - val_loss: 0.9369 - val_accuracy: 0.6680\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9980 - accuracy: 0.6496 - val_loss: 0.9541 - val_accuracy: 0.6606\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9763 - accuracy: 0.6546 - val_loss: 0.9022 - val_accuracy: 0.6834\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9426 - accuracy: 0.6689 - val_loss: 0.9121 - val_accuracy: 0.6796\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.9158 - accuracy: 0.6782 - val_loss: 0.8357 - val_accuracy: 0.7098\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8912 - accuracy: 0.6900 - val_loss: 0.8799 - val_accuracy: 0.6966\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.8726 - accuracy: 0.6936 - val_loss: 0.8737 - val_accuracy: 0.7002\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8553 - accuracy: 0.7034 - val_loss: 0.8374 - val_accuracy: 0.7108\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.8451 - accuracy: 0.7086 - val_loss: 0.8051 - val_accuracy: 0.7232\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8353 - accuracy: 0.7078 - val_loss: 0.7897 - val_accuracy: 0.7222\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.8131 - accuracy: 0.7149 - val_loss: 0.7854 - val_accuracy: 0.7240\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.8020 - accuracy: 0.7218 - val_loss: 0.7796 - val_accuracy: 0.7318\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7909 - accuracy: 0.7244 - val_loss: 0.8290 - val_accuracy: 0.7202\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7776 - accuracy: 0.7301 - val_loss: 0.7816 - val_accuracy: 0.7256\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7621 - accuracy: 0.7340 - val_loss: 0.7611 - val_accuracy: 0.7406\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7569 - accuracy: 0.7377 - val_loss: 0.8027 - val_accuracy: 0.7290\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7635 - accuracy: 0.7361 - val_loss: 0.7680 - val_accuracy: 0.7406\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7501 - accuracy: 0.7401 - val_loss: 0.7608 - val_accuracy: 0.7332\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 25s 18ms/step - loss: 0.7345 - accuracy: 0.7447 - val_loss: 0.7387 - val_accuracy: 0.7428\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7490 - accuracy: 0.7409 - val_loss: 0.7633 - val_accuracy: 0.7398\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7290 - accuracy: 0.7468 - val_loss: 0.7590 - val_accuracy: 0.7334\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7397 - accuracy: 0.7419 - val_loss: 0.7285 - val_accuracy: 0.7544\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7246 - accuracy: 0.7498 - val_loss: 0.7478 - val_accuracy: 0.7452\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7266 - accuracy: 0.7485 - val_loss: 0.7358 - val_accuracy: 0.7502\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7155 - accuracy: 0.7515 - val_loss: 0.7409 - val_accuracy: 0.7522\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7079 - accuracy: 0.7565 - val_loss: 0.7207 - val_accuracy: 0.7570\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7178 - accuracy: 0.7524 - val_loss: 0.7270 - val_accuracy: 0.7532\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7107 - accuracy: 0.7539 - val_loss: 0.7208 - val_accuracy: 0.7512\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7062 - accuracy: 0.7550 - val_loss: 0.7026 - val_accuracy: 0.7604\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7040 - accuracy: 0.7589 - val_loss: 0.7205 - val_accuracy: 0.7536\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 0.6928 - accuracy: 0.7632 - val_loss: 0.7235 - val_accuracy: 0.7550\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7076 - accuracy: 0.7551 - val_loss: 0.7462 - val_accuracy: 0.7394\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.6951 - accuracy: 0.7601 - val_loss: 0.7287 - val_accuracy: 0.7506\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 0.7095 - accuracy: 0.7582 - val_loss: 0.7478 - val_accuracy: 0.7426\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 2.3045 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.1066\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3030 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3031 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.1046\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3033 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3029 - accuracy: 0.0962 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0959 - val_loss: 2.3029 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 18ms/step - loss: 2.3056 - accuracy: 0.0963 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3029 - accuracy: 0.0961 - val_loss: 2.3028 - val_accuracy: 0.1014\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0963 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1025 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.0956\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 19ms/step - loss: 2.3054 - accuracy: 0.1031 - val_loss: 2.3029 - val_accuracy: 0.1006\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3030 - accuracy: 0.0953 - val_loss: 2.3033 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3029 - accuracy: 0.0944 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1015 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 27s 18ms/step - loss: 2.3050 - accuracy: 0.1009 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3029 - val_accuracy: 0.1046\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3031 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3026 - accuracy: 0.1016 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 26s 19ms/step - loss: 2.3026 - accuracy: 0.0973 - val_loss: 2.3025 - val_accuracy: 0.1066\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0956\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 26s 18ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.1066\n",
            "Ended optimizer Adam \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFaF8vyuLE5G"
      },
      "source": [
        "### Bigger 3 Conv Blocks with same padding\n",
        "\n",
        "In terms of more \"hidden\" layers (the layers of third dimension is bigger and bigger)\n",
        "And also more dense layers (one more with 1024 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTxq_H5q152I",
        "outputId": "dff8f5ef-b34c-49ee-9023-0d919a4083f9"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='Bigger_3ConvBlocks_same_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers:\n",
        "    results_of_model(model, opt[0], opt[1], n=n)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_3ConvBlocks_same_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              4195328   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 5,298,186\n",
            "Trainable params: 5,298,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 57s 17ms/step - loss: 2.0012 - accuracy: 0.2532 - val_loss: 1.5099 - val_accuracy: 0.4406\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 1.4821 - accuracy: 0.4588 - val_loss: 1.2999 - val_accuracy: 0.5302\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.2517 - accuracy: 0.5486 - val_loss: 1.3647 - val_accuracy: 0.5308\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.0973 - accuracy: 0.6106 - val_loss: 1.0303 - val_accuracy: 0.6468\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.9653 - accuracy: 0.6599 - val_loss: 1.0616 - val_accuracy: 0.6390\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.8738 - accuracy: 0.6946 - val_loss: 0.8826 - val_accuracy: 0.6878\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.7875 - accuracy: 0.7255 - val_loss: 0.8242 - val_accuracy: 0.7162\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.7260 - accuracy: 0.7463 - val_loss: 0.7944 - val_accuracy: 0.7276\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6721 - accuracy: 0.7671 - val_loss: 0.7940 - val_accuracy: 0.7328\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6276 - accuracy: 0.7834 - val_loss: 0.6942 - val_accuracy: 0.7686\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5732 - accuracy: 0.8052 - val_loss: 0.6724 - val_accuracy: 0.7718\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5396 - accuracy: 0.8155 - val_loss: 0.6733 - val_accuracy: 0.7762\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4960 - accuracy: 0.8278 - val_loss: 0.7030 - val_accuracy: 0.7784\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4623 - accuracy: 0.8400 - val_loss: 0.8753 - val_accuracy: 0.7428\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4484 - accuracy: 0.8472 - val_loss: 0.6275 - val_accuracy: 0.8026\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4186 - accuracy: 0.8550 - val_loss: 0.7123 - val_accuracy: 0.7822\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4109 - accuracy: 0.8614 - val_loss: 0.6379 - val_accuracy: 0.7972\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.3916 - accuracy: 0.8701 - val_loss: 0.6476 - val_accuracy: 0.7960\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.3862 - accuracy: 0.8710 - val_loss: 0.7328 - val_accuracy: 0.7978\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3655 - accuracy: 0.8781 - val_loss: 0.7562 - val_accuracy: 0.7630\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 24s 16ms/step - loss: 2.0082 - accuracy: 0.2474 - val_loss: 1.5488 - val_accuracy: 0.4444\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5061 - accuracy: 0.4503 - val_loss: 1.4256 - val_accuracy: 0.4986\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 1.2846 - accuracy: 0.5377 - val_loss: 1.2864 - val_accuracy: 0.5482\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1186 - accuracy: 0.6028 - val_loss: 1.1505 - val_accuracy: 0.5972\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.9833 - accuracy: 0.6546 - val_loss: 0.9897 - val_accuracy: 0.6466\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.8784 - accuracy: 0.6946 - val_loss: 0.9008 - val_accuracy: 0.6826\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.8002 - accuracy: 0.7198 - val_loss: 0.7979 - val_accuracy: 0.7238\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.7357 - accuracy: 0.7443 - val_loss: 0.7733 - val_accuracy: 0.7268\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.6655 - accuracy: 0.7666 - val_loss: 0.8599 - val_accuracy: 0.7114\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.6163 - accuracy: 0.7826 - val_loss: 0.7203 - val_accuracy: 0.7508\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5658 - accuracy: 0.8036 - val_loss: 0.8825 - val_accuracy: 0.7336\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5199 - accuracy: 0.8217 - val_loss: 0.6459 - val_accuracy: 0.7838\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4877 - accuracy: 0.8312 - val_loss: 0.6407 - val_accuracy: 0.7804\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4544 - accuracy: 0.8477 - val_loss: 0.7439 - val_accuracy: 0.7704\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4285 - accuracy: 0.8545 - val_loss: 0.6215 - val_accuracy: 0.7986\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4056 - accuracy: 0.8644 - val_loss: 0.6575 - val_accuracy: 0.7958\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3868 - accuracy: 0.8700 - val_loss: 0.7788 - val_accuracy: 0.7824\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.3741 - accuracy: 0.8759 - val_loss: 0.8291 - val_accuracy: 0.7692\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3751 - accuracy: 0.8754 - val_loss: 0.6741 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3631 - accuracy: 0.8806 - val_loss: 0.6181 - val_accuracy: 0.7984\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3527 - accuracy: 0.8833 - val_loss: 0.7241 - val_accuracy: 0.8084\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3474 - accuracy: 0.8879 - val_loss: 0.6809 - val_accuracy: 0.8040\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3393 - accuracy: 0.8903 - val_loss: 0.5968 - val_accuracy: 0.8078\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3381 - accuracy: 0.8891 - val_loss: 0.6703 - val_accuracy: 0.8040\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3329 - accuracy: 0.8931 - val_loss: 0.6476 - val_accuracy: 0.8020\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3381 - accuracy: 0.8929 - val_loss: 0.6302 - val_accuracy: 0.8044\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3345 - accuracy: 0.8914 - val_loss: 0.6890 - val_accuracy: 0.7928\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3333 - accuracy: 0.8924 - val_loss: 0.6071 - val_accuracy: 0.8024\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 2.0021 - accuracy: 0.2505 - val_loss: 1.6223 - val_accuracy: 0.4092\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5256 - accuracy: 0.4423 - val_loss: 1.4452 - val_accuracy: 0.4750\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.3027 - accuracy: 0.5286 - val_loss: 1.2224 - val_accuracy: 0.5636\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1383 - accuracy: 0.5935 - val_loss: 1.0072 - val_accuracy: 0.6424\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.0052 - accuracy: 0.6455 - val_loss: 0.9360 - val_accuracy: 0.6638\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.9139 - accuracy: 0.6800 - val_loss: 0.9130 - val_accuracy: 0.6872\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.8316 - accuracy: 0.7103 - val_loss: 0.9039 - val_accuracy: 0.6916\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.7612 - accuracy: 0.7343 - val_loss: 0.8244 - val_accuracy: 0.7210\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6984 - accuracy: 0.7579 - val_loss: 0.7433 - val_accuracy: 0.7462\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6491 - accuracy: 0.7733 - val_loss: 0.7466 - val_accuracy: 0.7478\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5991 - accuracy: 0.7899 - val_loss: 0.6964 - val_accuracy: 0.7688\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5478 - accuracy: 0.8102 - val_loss: 0.6587 - val_accuracy: 0.7766\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5191 - accuracy: 0.8208 - val_loss: 0.7351 - val_accuracy: 0.7578\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4848 - accuracy: 0.8358 - val_loss: 0.7622 - val_accuracy: 0.7478\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4733 - accuracy: 0.8390 - val_loss: 0.6504 - val_accuracy: 0.7880\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4448 - accuracy: 0.8491 - val_loss: 0.6159 - val_accuracy: 0.8000\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4204 - accuracy: 0.8571 - val_loss: 0.6041 - val_accuracy: 0.8044\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4082 - accuracy: 0.8649 - val_loss: 0.6197 - val_accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3821 - accuracy: 0.8739 - val_loss: 0.6920 - val_accuracy: 0.7866\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3867 - accuracy: 0.8720 - val_loss: 0.6390 - val_accuracy: 0.7970\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.3696 - accuracy: 0.8745 - val_loss: 0.6578 - val_accuracy: 0.8002\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.3696 - accuracy: 0.8791 - val_loss: 0.7022 - val_accuracy: 0.7914\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 24s 17ms/step - loss: 2.0291 - accuracy: 0.2433 - val_loss: 1.5532 - val_accuracy: 0.4300\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.5209 - accuracy: 0.4452 - val_loss: 1.5330 - val_accuracy: 0.4472\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.3088 - accuracy: 0.5272 - val_loss: 1.2446 - val_accuracy: 0.5542\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1504 - accuracy: 0.5905 - val_loss: 1.0820 - val_accuracy: 0.6084\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.0256 - accuracy: 0.6391 - val_loss: 0.9809 - val_accuracy: 0.6596\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.9288 - accuracy: 0.6718 - val_loss: 1.1560 - val_accuracy: 0.6078\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.8347 - accuracy: 0.7083 - val_loss: 0.8972 - val_accuracy: 0.6972\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.7635 - accuracy: 0.7339 - val_loss: 0.8336 - val_accuracy: 0.7194\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.7095 - accuracy: 0.7522 - val_loss: 0.7938 - val_accuracy: 0.7322\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6485 - accuracy: 0.7708 - val_loss: 0.8072 - val_accuracy: 0.7350\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6019 - accuracy: 0.7928 - val_loss: 0.7231 - val_accuracy: 0.7544\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5589 - accuracy: 0.8070 - val_loss: 0.6979 - val_accuracy: 0.7660\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5322 - accuracy: 0.8204 - val_loss: 0.7476 - val_accuracy: 0.7592\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5022 - accuracy: 0.8283 - val_loss: 0.6687 - val_accuracy: 0.7784\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4666 - accuracy: 0.8401 - val_loss: 0.6908 - val_accuracy: 0.7810\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4370 - accuracy: 0.8510 - val_loss: 0.6599 - val_accuracy: 0.7894\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4242 - accuracy: 0.8572 - val_loss: 0.6703 - val_accuracy: 0.7854\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4096 - accuracy: 0.8640 - val_loss: 0.6659 - val_accuracy: 0.7992\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3939 - accuracy: 0.8705 - val_loss: 0.6573 - val_accuracy: 0.8048\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3844 - accuracy: 0.8735 - val_loss: 0.7507 - val_accuracy: 0.7878\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3684 - accuracy: 0.8758 - val_loss: 0.6597 - val_accuracy: 0.8020\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3543 - accuracy: 0.8805 - val_loss: 0.6543 - val_accuracy: 0.7842\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3585 - accuracy: 0.8836 - val_loss: 0.7180 - val_accuracy: 0.7892\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3495 - accuracy: 0.8848 - val_loss: 0.6856 - val_accuracy: 0.7780\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3590 - accuracy: 0.8822 - val_loss: 0.5813 - val_accuracy: 0.8132\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3378 - accuracy: 0.8868 - val_loss: 0.7056 - val_accuracy: 0.7920\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3488 - accuracy: 0.8876 - val_loss: 0.6497 - val_accuracy: 0.7946\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3531 - accuracy: 0.8864 - val_loss: 0.6501 - val_accuracy: 0.8114\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3485 - accuracy: 0.8855 - val_loss: 0.6976 - val_accuracy: 0.8030\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3474 - accuracy: 0.8884 - val_loss: 0.7300 - val_accuracy: 0.7944\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 2.0290 - accuracy: 0.2375 - val_loss: 1.5275 - val_accuracy: 0.4414\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.4958 - accuracy: 0.4537 - val_loss: 1.3253 - val_accuracy: 0.5258\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.2688 - accuracy: 0.5428 - val_loss: 1.1205 - val_accuracy: 0.6054\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1028 - accuracy: 0.6082 - val_loss: 1.0213 - val_accuracy: 0.6330\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.9729 - accuracy: 0.6565 - val_loss: 0.9986 - val_accuracy: 0.6604\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.8874 - accuracy: 0.6861 - val_loss: 0.8932 - val_accuracy: 0.6862\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.8147 - accuracy: 0.7138 - val_loss: 0.7817 - val_accuracy: 0.7270\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.7422 - accuracy: 0.7406 - val_loss: 0.7932 - val_accuracy: 0.7204\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6883 - accuracy: 0.7625 - val_loss: 0.7750 - val_accuracy: 0.7366\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6376 - accuracy: 0.7826 - val_loss: 0.6901 - val_accuracy: 0.7630\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5966 - accuracy: 0.7979 - val_loss: 0.7476 - val_accuracy: 0.7546\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.5446 - accuracy: 0.8122 - val_loss: 0.6634 - val_accuracy: 0.7766\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.5107 - accuracy: 0.8240 - val_loss: 0.7175 - val_accuracy: 0.7554\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 23s 17ms/step - loss: 0.4947 - accuracy: 0.8322 - val_loss: 0.6697 - val_accuracy: 0.7774\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.4600 - accuracy: 0.8436 - val_loss: 0.6112 - val_accuracy: 0.7974\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4280 - accuracy: 0.8500 - val_loss: 0.6763 - val_accuracy: 0.8016\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4187 - accuracy: 0.8578 - val_loss: 0.7171 - val_accuracy: 0.7748\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3932 - accuracy: 0.8669 - val_loss: 0.6872 - val_accuracy: 0.7800\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3833 - accuracy: 0.8710 - val_loss: 0.6766 - val_accuracy: 0.7808\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3735 - accuracy: 0.8763 - val_loss: 0.6185 - val_accuracy: 0.7982\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3043 - accuracy: 0.0974 - val_loss: 2.3031 - val_accuracy: 0.0956\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3029 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.1046\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3026 - val_accuracy: 0.1014\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3031 - val_accuracy: 0.0936\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3028 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3183 - accuracy: 0.0982 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.1011 - val_loss: 2.3031 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1007 - val_loss: 2.3027 - val_accuracy: 0.1014\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.0979 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3033 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3029 - accuracy: 0.0962 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.0959 - val_loss: 2.3029 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3147 - accuracy: 0.0957 - val_loss: 2.3027 - val_accuracy: 0.0956\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1030\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.0959 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0932\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3030 - val_accuracy: 0.0936\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1025 - val_loss: 2.3028 - val_accuracy: 0.0964\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3030 - val_accuracy: 0.0956\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0936\n",
            "\n",
            "\n",
            "Model 3:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3186 - accuracy: 0.1008 - val_loss: 2.3028 - val_accuracy: 0.1006\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3032 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.1050\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3032 - val_accuracy: 0.0932\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.1002 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3029 - val_accuracy: 0.0964\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "\n",
            "\n",
            "Model 4:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 2.3133 - accuracy: 0.1012 - val_loss: 2.3029 - val_accuracy: 0.0932\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.1029 - val_loss: 2.3029 - val_accuracy: 0.0936\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3029 - accuracy: 0.1001 - val_loss: 2.3029 - val_accuracy: 0.1046\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3031 - val_accuracy: 0.0964\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.1014\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3027 - accuracy: 0.0955 - val_loss: 2.3031 - val_accuracy: 0.0936\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.0970 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3026 - accuracy: 0.1016 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3030 - val_accuracy: 0.0964\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3028 - val_accuracy: 0.1030\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3030 - val_accuracy: 0.0932\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3026 - accuracy: 0.0973 - val_loss: 2.3025 - val_accuracy: 0.1066\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0956\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3029 - val_accuracy: 0.0956\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0956\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.1066\n",
            "Ended optimizer Adam \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOYqxIZ4lBBv"
      },
      "source": [
        "### Bigger (CNN) 3 Conv Blocks with same padding\n",
        "\n",
        "In terms of more \"hidden\" layers (the layers of third dimension is bigger and bigger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Hjt7a1lBB3",
        "outputId": "27d04051-a4cf-4e32-bbce-aa9578d41511"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='Bigger_CNN_3ConvBlocks_same_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers[:1]:\n",
        "    results_of_model(model, opt[0], opt[1], n=1)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_CNN_3ConvBlocks_same_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,675,722\n",
            "Trainable params: 2,675,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 56s 16ms/step - loss: 2.0188 - accuracy: 0.2460 - val_loss: 1.5490 - val_accuracy: 0.4370\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 1.5159 - accuracy: 0.4486 - val_loss: 1.3601 - val_accuracy: 0.5030\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.2948 - accuracy: 0.5365 - val_loss: 1.4372 - val_accuracy: 0.5110\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.1500 - accuracy: 0.5900 - val_loss: 1.1402 - val_accuracy: 0.5972\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 1.0440 - accuracy: 0.6327 - val_loss: 0.9914 - val_accuracy: 0.6556\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9549 - accuracy: 0.6636 - val_loss: 1.0286 - val_accuracy: 0.6414\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.8890 - accuracy: 0.6876 - val_loss: 0.8492 - val_accuracy: 0.7006\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.8310 - accuracy: 0.7080 - val_loss: 0.8819 - val_accuracy: 0.7028\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.7794 - accuracy: 0.7295 - val_loss: 0.8056 - val_accuracy: 0.7238\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.7447 - accuracy: 0.7403 - val_loss: 0.7306 - val_accuracy: 0.7546\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.6968 - accuracy: 0.7590 - val_loss: 0.7618 - val_accuracy: 0.7346\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.6682 - accuracy: 0.7653 - val_loss: 0.6908 - val_accuracy: 0.7630\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.6310 - accuracy: 0.7801 - val_loss: 0.7080 - val_accuracy: 0.7606\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.6122 - accuracy: 0.7888 - val_loss: 0.7124 - val_accuracy: 0.7620\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5951 - accuracy: 0.7971 - val_loss: 0.7878 - val_accuracy: 0.7490\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5657 - accuracy: 0.8065 - val_loss: 0.6334 - val_accuracy: 0.7886\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5488 - accuracy: 0.8110 - val_loss: 0.6511 - val_accuracy: 0.7774\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5427 - accuracy: 0.8116 - val_loss: 0.6757 - val_accuracy: 0.7756\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5227 - accuracy: 0.8245 - val_loss: 0.6518 - val_accuracy: 0.7862\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.5094 - accuracy: 0.8278 - val_loss: 0.6123 - val_accuracy: 0.7902\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4989 - accuracy: 0.8307 - val_loss: 0.6123 - val_accuracy: 0.7932\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4863 - accuracy: 0.8342 - val_loss: 0.7021 - val_accuracy: 0.7798\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4798 - accuracy: 0.8366 - val_loss: 0.7150 - val_accuracy: 0.7868\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4628 - accuracy: 0.8423 - val_loss: 0.6895 - val_accuracy: 0.7754\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4522 - accuracy: 0.8426 - val_loss: 0.7313 - val_accuracy: 0.7822\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4529 - accuracy: 0.8475 - val_loss: 0.6039 - val_accuracy: 0.8076\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4448 - accuracy: 0.8495 - val_loss: 0.7433 - val_accuracy: 0.7578\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4390 - accuracy: 0.8539 - val_loss: 0.5861 - val_accuracy: 0.8032\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4228 - accuracy: 0.8565 - val_loss: 0.7253 - val_accuracy: 0.7770\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4221 - accuracy: 0.8565 - val_loss: 0.5737 - val_accuracy: 0.8122\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4123 - accuracy: 0.8614 - val_loss: 0.6170 - val_accuracy: 0.7984\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.4091 - accuracy: 0.8631 - val_loss: 0.6123 - val_accuracy: 0.8042\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.3992 - accuracy: 0.8632 - val_loss: 0.6091 - val_accuracy: 0.8068\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4019 - accuracy: 0.8680 - val_loss: 0.6127 - val_accuracy: 0.8084\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.3963 - accuracy: 0.8664 - val_loss: 0.5798 - val_accuracy: 0.8180\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_VfTaEvVQpk"
      },
      "source": [
        "### Bigger (CNN) 3 Conv Blocks with smaller padding\n",
        "\n",
        "In terms of more \"hidden\" layers (the layers of third dimension is bigger and bigger)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJv0oSl5VQpm",
        "outputId": "3d3cdcd0-9269-4853-b6ba-77fc0ba2cb63"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='Bigger_CNN_3ConvBlocks_smaller_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers[:1]:\n",
        "    results_of_model(model, opt[0], opt[1], n=3)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_CNN_3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,102,858\n",
            "Trainable params: 1,102,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.0866 - accuracy: 0.2050 - val_loss: 1.6593 - val_accuracy: 0.4004\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5967 - accuracy: 0.4149 - val_loss: 1.4230 - val_accuracy: 0.4816\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3832 - accuracy: 0.4993 - val_loss: 1.4917 - val_accuracy: 0.4810\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2563 - accuracy: 0.5467 - val_loss: 1.1927 - val_accuracy: 0.5766\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1427 - accuracy: 0.5952 - val_loss: 1.2623 - val_accuracy: 0.5704\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0634 - accuracy: 0.6230 - val_loss: 1.1560 - val_accuracy: 0.5856\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9947 - accuracy: 0.6483 - val_loss: 0.9342 - val_accuracy: 0.6708\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.9369 - accuracy: 0.6714 - val_loss: 1.0197 - val_accuracy: 0.6450\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8833 - accuracy: 0.6880 - val_loss: 0.8742 - val_accuracy: 0.6978\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8383 - accuracy: 0.7077 - val_loss: 0.8504 - val_accuracy: 0.7050\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7886 - accuracy: 0.7236 - val_loss: 0.8800 - val_accuracy: 0.6974\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7529 - accuracy: 0.7343 - val_loss: 0.7506 - val_accuracy: 0.7402\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7146 - accuracy: 0.7502 - val_loss: 0.7723 - val_accuracy: 0.7306\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6658 - accuracy: 0.7691 - val_loss: 0.8073 - val_accuracy: 0.7232\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.6518 - accuracy: 0.7741 - val_loss: 0.6999 - val_accuracy: 0.7600\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.6231 - accuracy: 0.7830 - val_loss: 0.6654 - val_accuracy: 0.7694\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.5917 - accuracy: 0.7949 - val_loss: 0.6816 - val_accuracy: 0.7702\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.5751 - accuracy: 0.8003 - val_loss: 0.6400 - val_accuracy: 0.7758\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.5492 - accuracy: 0.8117 - val_loss: 0.6642 - val_accuracy: 0.7814\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.5289 - accuracy: 0.8193 - val_loss: 0.6301 - val_accuracy: 0.7912\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.5125 - accuracy: 0.8250 - val_loss: 0.6601 - val_accuracy: 0.7772\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.5025 - accuracy: 0.8255 - val_loss: 0.6735 - val_accuracy: 0.7768\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4865 - accuracy: 0.8339 - val_loss: 0.6203 - val_accuracy: 0.7882\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4731 - accuracy: 0.8369 - val_loss: 0.6686 - val_accuracy: 0.7772\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4628 - accuracy: 0.8410 - val_loss: 0.7011 - val_accuracy: 0.7772\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.4475 - accuracy: 0.8512 - val_loss: 0.6164 - val_accuracy: 0.7956\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4482 - accuracy: 0.8449 - val_loss: 0.6660 - val_accuracy: 0.7874\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.4323 - accuracy: 0.8501 - val_loss: 0.6249 - val_accuracy: 0.8014\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.4203 - accuracy: 0.8558 - val_loss: 0.6892 - val_accuracy: 0.7766\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.4135 - accuracy: 0.8586 - val_loss: 0.5585 - val_accuracy: 0.8196\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4034 - accuracy: 0.8616 - val_loss: 0.6189 - val_accuracy: 0.8030\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.3923 - accuracy: 0.8657 - val_loss: 0.6045 - val_accuracy: 0.8078\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.3784 - accuracy: 0.8684 - val_loss: 0.5780 - val_accuracy: 0.8136\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.3803 - accuracy: 0.8697 - val_loss: 0.6363 - val_accuracy: 0.8072\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.3712 - accuracy: 0.8742 - val_loss: 0.5823 - val_accuracy: 0.8106\n",
            "\n",
            "\n",
            "Model 1:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.0723 - accuracy: 0.2141 - val_loss: 1.6932 - val_accuracy: 0.3682\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6283 - accuracy: 0.3981 - val_loss: 1.5116 - val_accuracy: 0.4552\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4137 - accuracy: 0.4852 - val_loss: 1.4131 - val_accuracy: 0.5070\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2691 - accuracy: 0.5430 - val_loss: 1.2458 - val_accuracy: 0.5552\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1635 - accuracy: 0.5837 - val_loss: 1.0882 - val_accuracy: 0.6136\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0723 - accuracy: 0.6205 - val_loss: 1.0098 - val_accuracy: 0.6382\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.0062 - accuracy: 0.6439 - val_loss: 0.9747 - val_accuracy: 0.6522\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9571 - accuracy: 0.6632 - val_loss: 0.9110 - val_accuracy: 0.6764\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8933 - accuracy: 0.6830 - val_loss: 0.9008 - val_accuracy: 0.6828\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8577 - accuracy: 0.6986 - val_loss: 0.8788 - val_accuracy: 0.6958\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8095 - accuracy: 0.7161 - val_loss: 0.8875 - val_accuracy: 0.6930\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7633 - accuracy: 0.7341 - val_loss: 0.7500 - val_accuracy: 0.7368\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7323 - accuracy: 0.7409 - val_loss: 0.7193 - val_accuracy: 0.7516\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6966 - accuracy: 0.7569 - val_loss: 0.7670 - val_accuracy: 0.7322\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6728 - accuracy: 0.7653 - val_loss: 0.7058 - val_accuracy: 0.7610\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6363 - accuracy: 0.7821 - val_loss: 0.7012 - val_accuracy: 0.7610\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6226 - accuracy: 0.7830 - val_loss: 0.7148 - val_accuracy: 0.7592\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5893 - accuracy: 0.7955 - val_loss: 0.6656 - val_accuracy: 0.7744\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.5852 - accuracy: 0.7964 - val_loss: 0.6769 - val_accuracy: 0.7696\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5503 - accuracy: 0.8068 - val_loss: 0.7212 - val_accuracy: 0.7622\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5394 - accuracy: 0.8120 - val_loss: 0.6609 - val_accuracy: 0.7846\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5117 - accuracy: 0.8242 - val_loss: 0.6073 - val_accuracy: 0.7940\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4916 - accuracy: 0.8306 - val_loss: 0.6596 - val_accuracy: 0.7850\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4849 - accuracy: 0.8336 - val_loss: 0.6319 - val_accuracy: 0.7972\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4721 - accuracy: 0.8384 - val_loss: 0.6302 - val_accuracy: 0.7934\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4630 - accuracy: 0.8415 - val_loss: 0.6973 - val_accuracy: 0.7784\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4432 - accuracy: 0.8489 - val_loss: 0.6131 - val_accuracy: 0.8014\n",
            "\n",
            "\n",
            "Model 2:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 2.0709 - accuracy: 0.2120 - val_loss: 1.7313 - val_accuracy: 0.3558\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.6483 - accuracy: 0.3911 - val_loss: 1.5130 - val_accuracy: 0.4546\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4311 - accuracy: 0.4823 - val_loss: 1.3402 - val_accuracy: 0.5184\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.2990 - accuracy: 0.5321 - val_loss: 1.2004 - val_accuracy: 0.5760\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1833 - accuracy: 0.5796 - val_loss: 1.1576 - val_accuracy: 0.5846\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1033 - accuracy: 0.6092 - val_loss: 1.0866 - val_accuracy: 0.6192\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 1.0316 - accuracy: 0.6345 - val_loss: 1.1225 - val_accuracy: 0.6092\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.9675 - accuracy: 0.6582 - val_loss: 1.0528 - val_accuracy: 0.6390\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9082 - accuracy: 0.6797 - val_loss: 0.9054 - val_accuracy: 0.6768\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8625 - accuracy: 0.6970 - val_loss: 0.8947 - val_accuracy: 0.6824\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8162 - accuracy: 0.7106 - val_loss: 0.7663 - val_accuracy: 0.7270\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7624 - accuracy: 0.7343 - val_loss: 0.7906 - val_accuracy: 0.7252\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7319 - accuracy: 0.7435 - val_loss: 0.9379 - val_accuracy: 0.6880\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.6974 - accuracy: 0.7568 - val_loss: 0.8158 - val_accuracy: 0.7216\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6618 - accuracy: 0.7695 - val_loss: 0.7752 - val_accuracy: 0.7360\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.6458 - accuracy: 0.7763 - val_loss: 0.6791 - val_accuracy: 0.7648\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6141 - accuracy: 0.7894 - val_loss: 0.6578 - val_accuracy: 0.7684\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5908 - accuracy: 0.7971 - val_loss: 0.6322 - val_accuracy: 0.7832\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5701 - accuracy: 0.8017 - val_loss: 0.6525 - val_accuracy: 0.7738\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.5555 - accuracy: 0.8083 - val_loss: 0.6850 - val_accuracy: 0.7688\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5331 - accuracy: 0.8143 - val_loss: 0.6188 - val_accuracy: 0.7864\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.5159 - accuracy: 0.8238 - val_loss: 0.6361 - val_accuracy: 0.7856\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5005 - accuracy: 0.8288 - val_loss: 0.6216 - val_accuracy: 0.7912\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.4884 - accuracy: 0.8319 - val_loss: 0.5885 - val_accuracy: 0.7982\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4626 - accuracy: 0.8389 - val_loss: 0.6207 - val_accuracy: 0.7858\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4616 - accuracy: 0.8408 - val_loss: 0.6206 - val_accuracy: 0.7982\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4477 - accuracy: 0.8450 - val_loss: 0.5689 - val_accuracy: 0.8100\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.4448 - accuracy: 0.8472 - val_loss: 0.5892 - val_accuracy: 0.7994\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4417 - accuracy: 0.8473 - val_loss: 0.5794 - val_accuracy: 0.8078\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4191 - accuracy: 0.8557 - val_loss: 0.6591 - val_accuracy: 0.7886\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4159 - accuracy: 0.8567 - val_loss: 0.5812 - val_accuracy: 0.8054\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.4018 - accuracy: 0.8631 - val_loss: 0.5602 - val_accuracy: 0.8140\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.3947 - accuracy: 0.8647 - val_loss: 0.7087 - val_accuracy: 0.7716\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.3906 - accuracy: 0.8666 - val_loss: 0.5700 - val_accuracy: 0.8118\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.3875 - accuracy: 0.8694 - val_loss: 0.7483 - val_accuracy: 0.7750\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.3815 - accuracy: 0.8687 - val_loss: 0.5847 - val_accuracy: 0.8182\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.3723 - accuracy: 0.8732 - val_loss: 0.5436 - val_accuracy: 0.8246\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.3578 - accuracy: 0.8799 - val_loss: 0.5449 - val_accuracy: 0.8176\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.3648 - accuracy: 0.8760 - val_loss: 0.6470 - val_accuracy: 0.8088\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.3597 - accuracy: 0.8789 - val_loss: 0.5866 - val_accuracy: 0.8140\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.3539 - accuracy: 0.8801 - val_loss: 0.6286 - val_accuracy: 0.8128\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.3518 - accuracy: 0.8815 - val_loss: 0.5686 - val_accuracy: 0.8196\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBbiWcnASQb7"
      },
      "source": [
        "### Bigger 3 Conv Blocks with smaller padding\n",
        "\n",
        "In terms of more \"hidden\" layers (the layers of third dimension is bigger and bigger)\n",
        "And also more dense layers (one more with 1024 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgVvWs3lSQb8",
        "outputId": "d3c0f5f1-f396-467e-8694-b1725f8f1489"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='Bigger_3ConvBlocks_smaller_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers[:1]:\n",
        "    results_of_model(model, opt[0], opt[1], n=1)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,152,458\n",
            "Trainable params: 2,152,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 47s 11ms/step - loss: 2.0615 - accuracy: 0.2178 - val_loss: 1.6351 - val_accuracy: 0.3980\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5638 - accuracy: 0.4270 - val_loss: 1.3991 - val_accuracy: 0.4872\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3447 - accuracy: 0.5143 - val_loss: 1.6223 - val_accuracy: 0.4504\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2049 - accuracy: 0.5708 - val_loss: 1.1448 - val_accuracy: 0.6070\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0869 - accuracy: 0.6184 - val_loss: 1.1009 - val_accuracy: 0.6122\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9984 - accuracy: 0.6474 - val_loss: 1.2420 - val_accuracy: 0.5870\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9276 - accuracy: 0.6751 - val_loss: 0.8813 - val_accuracy: 0.6956\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8624 - accuracy: 0.7008 - val_loss: 0.9613 - val_accuracy: 0.6716\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8046 - accuracy: 0.7164 - val_loss: 0.7980 - val_accuracy: 0.7228\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7662 - accuracy: 0.7341 - val_loss: 0.7431 - val_accuracy: 0.7406\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.7019 - accuracy: 0.7586 - val_loss: 0.7866 - val_accuracy: 0.7268\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6707 - accuracy: 0.7701 - val_loss: 0.7678 - val_accuracy: 0.7376\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6311 - accuracy: 0.7788 - val_loss: 0.7752 - val_accuracy: 0.7356\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.6027 - accuracy: 0.7916 - val_loss: 0.7576 - val_accuracy: 0.7426\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.5854 - accuracy: 0.7994 - val_loss: 0.6395 - val_accuracy: 0.7754\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5535 - accuracy: 0.8102 - val_loss: 0.6432 - val_accuracy: 0.7806\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5225 - accuracy: 0.8193 - val_loss: 0.6922 - val_accuracy: 0.7648\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.5142 - accuracy: 0.8252 - val_loss: 0.6910 - val_accuracy: 0.7686\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 14s 10ms/step - loss: 0.4988 - accuracy: 0.8276 - val_loss: 0.6577 - val_accuracy: 0.7876\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 15s 10ms/step - loss: 0.4813 - accuracy: 0.8356 - val_loss: 0.6434 - val_accuracy: 0.7862\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7mC0nVNMgqO"
      },
      "source": [
        "## 4 Conv Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgdNN_12uIzH"
      },
      "source": [
        "### 4 Conv Blocks smaller padding\n",
        "\n",
        "Padding in the last conv block have to be same because of negative result shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0w10ZT8L28Q",
        "outputId": "2989bbbf-84d8-4a1e-c9f3-f50ca8e34c09"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='4ConvBlocks_smaller_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers[:1]:\n",
        "    results_of_model(model, opt[0], opt[1], n=1)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"4ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 2, 2, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 2,610,954\n",
            "Trainable params: 2,610,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 20s 13ms/step - loss: 2.1072 - accuracy: 0.1930 - val_loss: 1.6672 - val_accuracy: 0.3796\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6159 - accuracy: 0.4057 - val_loss: 1.4372 - val_accuracy: 0.4668\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.3821 - accuracy: 0.4991 - val_loss: 1.7492 - val_accuracy: 0.4186\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.2451 - accuracy: 0.5481 - val_loss: 1.2928 - val_accuracy: 0.5500\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.1312 - accuracy: 0.5991 - val_loss: 1.1838 - val_accuracy: 0.5886\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0437 - accuracy: 0.6301 - val_loss: 1.0844 - val_accuracy: 0.6138\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.9671 - accuracy: 0.6609 - val_loss: 0.9539 - val_accuracy: 0.6728\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.8997 - accuracy: 0.6816 - val_loss: 0.8942 - val_accuracy: 0.6910\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.8398 - accuracy: 0.7058 - val_loss: 0.8591 - val_accuracy: 0.7016\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.8006 - accuracy: 0.7232 - val_loss: 0.7809 - val_accuracy: 0.7310\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 19s 13ms/step - loss: 0.7418 - accuracy: 0.7457 - val_loss: 0.8144 - val_accuracy: 0.7198\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.7011 - accuracy: 0.7601 - val_loss: 0.8006 - val_accuracy: 0.7310\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.6681 - accuracy: 0.7713 - val_loss: 0.7026 - val_accuracy: 0.7690\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.6314 - accuracy: 0.7847 - val_loss: 0.7420 - val_accuracy: 0.7512\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.6011 - accuracy: 0.7972 - val_loss: 0.7051 - val_accuracy: 0.7666\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.5714 - accuracy: 0.8049 - val_loss: 0.6606 - val_accuracy: 0.7824\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.5464 - accuracy: 0.8151 - val_loss: 0.7019 - val_accuracy: 0.7822\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.5327 - accuracy: 0.8184 - val_loss: 0.6325 - val_accuracy: 0.7918\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.5057 - accuracy: 0.8274 - val_loss: 0.6382 - val_accuracy: 0.7902\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.4935 - accuracy: 0.8341 - val_loss: 0.5974 - val_accuracy: 0.8020\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.4825 - accuracy: 0.8388 - val_loss: 0.6619 - val_accuracy: 0.7824\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.4739 - accuracy: 0.8440 - val_loss: 0.6462 - val_accuracy: 0.7936\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.4647 - accuracy: 0.8472 - val_loss: 0.6471 - val_accuracy: 0.7974\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.4454 - accuracy: 0.8525 - val_loss: 0.6082 - val_accuracy: 0.7936\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 18s 13ms/step - loss: 0.4380 - accuracy: 0.8533 - val_loss: 0.6108 - val_accuracy: 0.7964\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7McwJgikeZpy"
      },
      "source": [
        "### 4 Conv Blocks same padding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wWu18OleZqF",
        "outputId": "a6ffe59c-c6c6-414f-ec05-209a029fe3fc"
      },
      "source": [
        "set_seed(123)\n",
        "model = Sequential(name='4ConvBlocks_same_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "for opt in optimizers[:1]:\n",
        "    results_of_model(model, opt[0], opt[1], n=1)\n",
        "    print(f'Ended optimizer {opt[1]} \\n\\n\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"4ConvBlocks_same_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 4,971,274\n",
            "Trainable params: 4,971,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n",
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 2.0574 - accuracy: 0.2195 - val_loss: 1.5828 - val_accuracy: 0.4096\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5598 - accuracy: 0.4228 - val_loss: 1.3487 - val_accuracy: 0.5044\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3234 - accuracy: 0.5160 - val_loss: 1.4592 - val_accuracy: 0.4980\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.1741 - accuracy: 0.5751 - val_loss: 1.1401 - val_accuracy: 0.6030\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 1.0484 - accuracy: 0.6255 - val_loss: 1.0322 - val_accuracy: 0.6340\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9512 - accuracy: 0.6656 - val_loss: 1.4498 - val_accuracy: 0.5516\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.8689 - accuracy: 0.6945 - val_loss: 0.9025 - val_accuracy: 0.6838\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7995 - accuracy: 0.7214 - val_loss: 0.8221 - val_accuracy: 0.7166\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.7382 - accuracy: 0.7454 - val_loss: 0.7435 - val_accuracy: 0.7504\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.6853 - accuracy: 0.7654 - val_loss: 0.7999 - val_accuracy: 0.7338\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.6297 - accuracy: 0.7836 - val_loss: 0.7481 - val_accuracy: 0.7410\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5887 - accuracy: 0.7989 - val_loss: 0.6735 - val_accuracy: 0.7770\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 20s 15ms/step - loss: 0.5521 - accuracy: 0.8093 - val_loss: 0.6678 - val_accuracy: 0.7746\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5171 - accuracy: 0.8239 - val_loss: 0.7399 - val_accuracy: 0.7616\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.5034 - accuracy: 0.8289 - val_loss: 0.6834 - val_accuracy: 0.7794\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4691 - accuracy: 0.8402 - val_loss: 0.8003 - val_accuracy: 0.7694\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4626 - accuracy: 0.8475 - val_loss: 0.7812 - val_accuracy: 0.7744\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4527 - accuracy: 0.8494 - val_loss: 0.6350 - val_accuracy: 0.8004\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4480 - accuracy: 0.8512 - val_loss: 0.7499 - val_accuracy: 0.7860\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4284 - accuracy: 0.8597 - val_loss: 0.7807 - val_accuracy: 0.7506\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4189 - accuracy: 0.8601 - val_loss: 0.6684 - val_accuracy: 0.7854\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4243 - accuracy: 0.8597 - val_loss: 0.7227 - val_accuracy: 0.7762\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 20s 14ms/step - loss: 0.4235 - accuracy: 0.8611 - val_loss: 0.7005 - val_accuracy: 0.7924\n",
            "Ended optimizer RMSProp \n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_q8DqtYz9uN"
      },
      "source": [
        "## Plots of models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORUaPv6l0Smh"
      },
      "source": [
        "first\n",
        "Epoch 1/2\n",
        "1407/1407 [==============================] - 15s 10ms/step - loss: 2.0614 - accuracy: 0.2299 - val_loss: 1.6010 - val_accuracy: 0.4238\n",
        "Epoch 2/2\n",
        "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5858 - accuracy: 0.4281 - val_loss: 1.4363 - val_accuracy: 0.4874\n",
        "Ended optimizer RMSProp \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Epoch 1/2\n",
        "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8373 - accuracy: 0.3183 - val_loss: 1.3230 - val_accuracy: 0.5248\n",
        "Epoch 2/2\n",
        "1407/1407 [==============================] - 13s 10ms/step - loss: 1.2720 - accuracy: 0.5422 - val_loss: 1.0521 - val_accuracy: 0.6216\n",
        "Ended optimizer Adam \n",
        "\n",
        "\n",
        "second \n",
        "Epoch 1/2\n",
        "1407/1407 [==============================] - 15s 10ms/step - loss: 2.0246 - accuracy: 0.2513 - val_loss: 1.5694 - val_accuracy: 0.4354\n",
        "Epoch 2/2\n",
        "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5480 - accuracy: 0.4408 - val_loss: 1.3716 - val_accuracy: 0.5090\n",
        "Ended optimizer RMSProp \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Epoch 1/2\n",
        "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8311 - accuracy: 0.3189 - val_loss: 1.2061 - val_accuracy: 0.5686\n",
        "Epoch 2/2\n",
        "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1937 - accuracy: 0.5746 - val_loss: 1.0043 - val_accuracy: 0.6486\n",
        "Ended optimizer Adam "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "Sml6tlhy0HpX",
        "outputId": "394083cc-2c44-42a3-e9bd-a4cf0d463c4e"
      },
      "source": [
        "directory = 'drive/MyDrive/Colab Notebooks/pickles/'\n",
        "files = os.listdir(directory)\n",
        "files_Adam = [file for file in files[1:] if file.split('-')[1]=='Adam']\n",
        "files_RMSProp = [file for file in files[1:] if file.split('-')[1]=='RMSProp']\n",
        "all_files = [files_RMSProp, files_Adam]\n",
        "\n",
        "acc = {'Adam': {}, 'RMSProp': {}}   #1\n",
        "loss = {'Adam': {}, 'RMSProp': {}}  #3\n",
        "for file_list in all_files:\n",
        "  for filename in file_list:\n",
        "    model_name = filename.split('-')[0]\n",
        "    opt_name = filename.split('-')[1]\n",
        "    with open(directory + filename, 'rb') as f:\n",
        "      history = pickle.load(f)\n",
        "      a = []\n",
        "      l = []\n",
        "      for i in range(len(history)):\n",
        "        a.append(history[i][1][-6])\n",
        "        l.append(history[i][3][-6])\n",
        "      if len(a) < n:\n",
        "        # if too few samples - append samples with mean\n",
        "        a = a + [sum(a)/len(a)] * (n - len(a))\n",
        "        l = l + [sum(l)/len(l)] * (n - len(l))\n",
        "        acc['Adam'][model_name] = [0] * n\n",
        "        loss['Adam'][model_name] = [0] * n\n",
        "      acc[opt_name][model_name] = a\n",
        "      loss[opt_name][model_name] = l\n",
        "\n",
        "measures = [acc, loss]\n",
        "measure_names = ['Accuracy', 'Loss']\n",
        "for index in range(2):\n",
        "  plt.subplots(2, 1)\n",
        "  plt.subplots_adjust(hspace=0.6)\n",
        "  for i, opt_name in enumerate(acc.keys()):\n",
        "    plt.subplot(2, 1, i+1)\n",
        "    data = measures[index][opt_name]\n",
        "    data = pd.DataFrame(data)    \n",
        "    data = data.reindex(natsorted(data.columns), axis=1)\n",
        "    labels = data.columns\n",
        "    plt.boxplot(np.array(data))\n",
        "    plt.title(f'{measure_names[index]} for optimizer {opt_name}')\n",
        "  ax = plt.gca()\n",
        "  ax.set_xticklabels(labels=labels, rotation=90)\n",
        "  plt.show()\n",
        "\n",
        "# plt.savefig(\"plots/activations/{0}_{1}_loss_boxplot.png\".format(dataset.name, dataset.size),\n",
        "#             dpi=100, bbox_inches=\"tight\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHiZEOMvzcNt"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GABQyCYQ_Oj3"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Co_y1x_myV"
      },
      "source": [
        "opt = optimizers[0]\n",
        "data_augmentation = True\n",
        "\n",
        "set_seed(123)\n",
        "model = Sequential(name='Bigger_CNN_3ConvBlocks_smaller_padding')\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(256, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFxtaQFi_V_Z"
      },
      "source": [
        "### Shift=0.05, Flip=True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF9rQUT-1zkE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e7c9d18-aabf-4109-d28c-5622bbf485db"
      },
      "source": [
        "shift = 0.05\n",
        "horizontal_flip = True\n",
        "rotation = 0\n",
        "workers = 4\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "results_of_model(model, opt[0], opt[1], n=1, plot=True,\n",
        "                 data_augmentation=data_augmentation, \n",
        "                 shift=shift, horizontal_flip=horizontal_flip, rotation=rotation,\n",
        "                 workers=workers, early_stopping=early_stopping)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_CNN_3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,102,858\n",
            "Trainable params: 1,102,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 35s 24ms/step - loss: 2.0999 - accuracy: 0.2007 - val_loss: 1.6417 - val_accuracy: 0.3980\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6490 - accuracy: 0.3907 - val_loss: 1.4452 - val_accuracy: 0.4754\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.4593 - accuracy: 0.4679 - val_loss: 1.3221 - val_accuracy: 0.5322\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.3251 - accuracy: 0.5194 - val_loss: 1.1777 - val_accuracy: 0.5770\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.2348 - accuracy: 0.5553 - val_loss: 1.3104 - val_accuracy: 0.5418\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.1494 - accuracy: 0.5881 - val_loss: 1.0368 - val_accuracy: 0.6442\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.0824 - accuracy: 0.6185 - val_loss: 1.0617 - val_accuracy: 0.6296\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.0211 - accuracy: 0.6450 - val_loss: 0.9817 - val_accuracy: 0.6510\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.9696 - accuracy: 0.6619 - val_loss: 0.9326 - val_accuracy: 0.6690\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.9267 - accuracy: 0.6732 - val_loss: 0.8615 - val_accuracy: 0.6976\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.8839 - accuracy: 0.6886 - val_loss: 0.8563 - val_accuracy: 0.7092\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.8401 - accuracy: 0.7057 - val_loss: 0.7978 - val_accuracy: 0.7256\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.8031 - accuracy: 0.7214 - val_loss: 0.7822 - val_accuracy: 0.7344\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7721 - accuracy: 0.7305 - val_loss: 0.7507 - val_accuracy: 0.7438\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7506 - accuracy: 0.7392 - val_loss: 0.7813 - val_accuracy: 0.7322\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7238 - accuracy: 0.7513 - val_loss: 0.6996 - val_accuracy: 0.7636\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7020 - accuracy: 0.7563 - val_loss: 0.7266 - val_accuracy: 0.7484\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6833 - accuracy: 0.7645 - val_loss: 0.6772 - val_accuracy: 0.7670\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6678 - accuracy: 0.7720 - val_loss: 0.6160 - val_accuracy: 0.7902\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6521 - accuracy: 0.7763 - val_loss: 0.6960 - val_accuracy: 0.7668\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6393 - accuracy: 0.7828 - val_loss: 0.6777 - val_accuracy: 0.7754\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6230 - accuracy: 0.7852 - val_loss: 0.6710 - val_accuracy: 0.7762\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.6165 - accuracy: 0.7897 - val_loss: 0.6306 - val_accuracy: 0.7866\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5992 - accuracy: 0.7970 - val_loss: 0.5933 - val_accuracy: 0.8036\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5984 - accuracy: 0.7951 - val_loss: 0.5903 - val_accuracy: 0.8018\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5927 - accuracy: 0.7972 - val_loss: 0.5560 - val_accuracy: 0.8124\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5810 - accuracy: 0.8041 - val_loss: 0.6999 - val_accuracy: 0.7782\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5805 - accuracy: 0.8031 - val_loss: 0.5928 - val_accuracy: 0.8080\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5649 - accuracy: 0.8075 - val_loss: 0.6185 - val_accuracy: 0.7946\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5643 - accuracy: 0.8103 - val_loss: 0.5696 - val_accuracy: 0.8126\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.5603 - accuracy: 0.8137 - val_loss: 0.6055 - val_accuracy: 0.8064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([0.2717111110687256,\n",
              "   0.4099777638912201,\n",
              "   0.4828000068664551,\n",
              "   0.5327555537223816,\n",
              "   0.5643555521965027,\n",
              "   0.593844473361969,\n",
              "   0.621577799320221,\n",
              "   0.6462888717651367,\n",
              "   0.6616888642311096,\n",
              "   0.6763111352920532,\n",
              "   0.691444456577301,\n",
              "   0.7082444429397583,\n",
              "   0.7230444550514221,\n",
              "   0.7310000061988831,\n",
              "   0.7411999702453613,\n",
              "   0.7496444582939148,\n",
              "   0.757444441318512,\n",
              "   0.7648666501045227,\n",
              "   0.7716000080108643,\n",
              "   0.777044415473938,\n",
              "   0.7810666561126709,\n",
              "   0.7845333218574524,\n",
              "   0.7885110974311829,\n",
              "   0.7933333516120911,\n",
              "   0.7972221970558167,\n",
              "   0.7973777651786804,\n",
              "   0.8030444383621216,\n",
              "   0.8033778071403503,\n",
              "   0.8061333298683167,\n",
              "   0.8088666796684265,\n",
              "   0.81086665391922],\n",
              "  [0.39800000190734863,\n",
              "   0.47540000081062317,\n",
              "   0.5321999788284302,\n",
              "   0.5770000219345093,\n",
              "   0.5418000221252441,\n",
              "   0.6442000269889832,\n",
              "   0.6295999884605408,\n",
              "   0.6510000228881836,\n",
              "   0.6690000295639038,\n",
              "   0.6976000070571899,\n",
              "   0.7092000246047974,\n",
              "   0.725600004196167,\n",
              "   0.7343999743461609,\n",
              "   0.7437999844551086,\n",
              "   0.732200026512146,\n",
              "   0.7635999917984009,\n",
              "   0.7483999729156494,\n",
              "   0.7670000195503235,\n",
              "   0.7901999950408936,\n",
              "   0.7667999863624573,\n",
              "   0.7753999829292297,\n",
              "   0.776199996471405,\n",
              "   0.7865999937057495,\n",
              "   0.803600013256073,\n",
              "   0.801800012588501,\n",
              "   0.8123999834060669,\n",
              "   0.7781999707221985,\n",
              "   0.8080000281333923,\n",
              "   0.7946000099182129,\n",
              "   0.8126000165939331,\n",
              "   0.8064000010490417],\n",
              "  [1.9422599077224731,\n",
              "   1.5991475582122803,\n",
              "   1.422291874885559,\n",
              "   1.3008216619491577,\n",
              "   1.2108649015426636,\n",
              "   1.1335562467575073,\n",
              "   1.0700023174285889,\n",
              "   1.0126396417617798,\n",
              "   0.9634658098220825,\n",
              "   0.9202868342399597,\n",
              "   0.8777156472206116,\n",
              "   0.8336334824562073,\n",
              "   0.8000386357307434,\n",
              "   0.7751678824424744,\n",
              "   0.7454747557640076,\n",
              "   0.7232950329780579,\n",
              "   0.7013162970542908,\n",
              "   0.6813953518867493,\n",
              "   0.6675175428390503,\n",
              "   0.6518676280975342,\n",
              "   0.6418070197105408,\n",
              "   0.6245312690734863,\n",
              "   0.6217080950737,\n",
              "   0.6078329086303711,\n",
              "   0.5985626578330994,\n",
              "   0.5934823751449585,\n",
              "   0.58193039894104,\n",
              "   0.5794042944908142,\n",
              "   0.5675832033157349,\n",
              "   0.5665538907051086,\n",
              "   0.5655393600463867],\n",
              "  [1.6416728496551514,\n",
              "   1.4451674222946167,\n",
              "   1.3221235275268555,\n",
              "   1.177747130393982,\n",
              "   1.310368299484253,\n",
              "   1.036807656288147,\n",
              "   1.0616894960403442,\n",
              "   0.981666088104248,\n",
              "   0.9325728416442871,\n",
              "   0.8615235090255737,\n",
              "   0.8563117980957031,\n",
              "   0.7977988123893738,\n",
              "   0.7822328209877014,\n",
              "   0.7507432699203491,\n",
              "   0.7813049554824829,\n",
              "   0.6996207237243652,\n",
              "   0.7266424298286438,\n",
              "   0.6771849393844604,\n",
              "   0.6159844398498535,\n",
              "   0.6960471868515015,\n",
              "   0.677681028842926,\n",
              "   0.6709672808647156,\n",
              "   0.6306031942367554,\n",
              "   0.5933288931846619,\n",
              "   0.5903425216674805,\n",
              "   0.5560358166694641,\n",
              "   0.6999232172966003,\n",
              "   0.5928370356559753,\n",
              "   0.6185479760169983,\n",
              "   0.5696035623550415,\n",
              "   0.6055082082748413])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89dq-QTELvjX"
      },
      "source": [
        "### Shift=0.05, Flip=True, rotation=10, patience=5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Giru43uILvjZ",
        "outputId": "e695979a-2fde-4ffe-b4c5-a25fe754c391"
      },
      "source": [
        "shift = 0.05\n",
        "horizontal_flip = True\n",
        "rotation = 10\n",
        "workers = 2  # just to check if time is different\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "results_of_model(model, opt[0], opt[1], n=1, plot=True,\n",
        "                 data_augmentation=data_augmentation, \n",
        "                 shift=shift, horizontal_flip=horizontal_flip, rotation=rotation,\n",
        "                 workers=workers, early_stopping=early_stopping)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_CNN_3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,102,858\n",
            "Trainable params: 1,102,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 2.0979 - accuracy: 0.2039 - val_loss: 1.6430 - val_accuracy: 0.3946\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6388 - accuracy: 0.3963 - val_loss: 1.4115 - val_accuracy: 0.4894\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.4580 - accuracy: 0.4707 - val_loss: 1.3881 - val_accuracy: 0.5064\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.3274 - accuracy: 0.5184 - val_loss: 1.2082 - val_accuracy: 0.5624\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.2294 - accuracy: 0.5625 - val_loss: 1.2076 - val_accuracy: 0.5782\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.1501 - accuracy: 0.5914 - val_loss: 1.0266 - val_accuracy: 0.6314\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.0781 - accuracy: 0.6163 - val_loss: 1.0533 - val_accuracy: 0.6348\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.0370 - accuracy: 0.6349 - val_loss: 1.1086 - val_accuracy: 0.6172\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.9875 - accuracy: 0.6546 - val_loss: 1.1280 - val_accuracy: 0.6226\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.9429 - accuracy: 0.6684 - val_loss: 0.9069 - val_accuracy: 0.6850\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.9005 - accuracy: 0.6851 - val_loss: 0.8806 - val_accuracy: 0.6912\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.8620 - accuracy: 0.6973 - val_loss: 0.8710 - val_accuracy: 0.6960\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.8252 - accuracy: 0.7130 - val_loss: 0.8020 - val_accuracy: 0.7268\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.8043 - accuracy: 0.7212 - val_loss: 0.7637 - val_accuracy: 0.7396\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.7653 - accuracy: 0.7344 - val_loss: 0.7818 - val_accuracy: 0.7302\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.7576 - accuracy: 0.7405 - val_loss: 0.7098 - val_accuracy: 0.7520\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.7219 - accuracy: 0.7498 - val_loss: 0.6893 - val_accuracy: 0.7612\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.7064 - accuracy: 0.7578 - val_loss: 0.7433 - val_accuracy: 0.7424\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6866 - accuracy: 0.7634 - val_loss: 0.6780 - val_accuracy: 0.7672\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6766 - accuracy: 0.7691 - val_loss: 0.6758 - val_accuracy: 0.7686\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6730 - accuracy: 0.7691 - val_loss: 0.6286 - val_accuracy: 0.7868\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6604 - accuracy: 0.7743 - val_loss: 0.6262 - val_accuracy: 0.7864\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6332 - accuracy: 0.7849 - val_loss: 0.7143 - val_accuracy: 0.7676\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6327 - accuracy: 0.7862 - val_loss: 0.7023 - val_accuracy: 0.7778\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6357 - accuracy: 0.7835 - val_loss: 0.6433 - val_accuracy: 0.7850\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6196 - accuracy: 0.7879 - val_loss: 0.7153 - val_accuracy: 0.7624\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6089 - accuracy: 0.7940 - val_loss: 0.6268 - val_accuracy: 0.7868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([0.27355554699897766,\n",
              "   0.4172666668891907,\n",
              "   0.48604443669319153,\n",
              "   0.5304444432258606,\n",
              "   0.5701777935028076,\n",
              "   0.5966444611549377,\n",
              "   0.618755578994751,\n",
              "   0.6405777931213379,\n",
              "   0.6574888825416565,\n",
              "   0.6746222376823425,\n",
              "   0.6870889067649841,\n",
              "   0.6988444328308105,\n",
              "   0.7130444645881653,\n",
              "   0.7240222096443176,\n",
              "   0.7331555485725403,\n",
              "   0.7412444353103638,\n",
              "   0.7503555417060852,\n",
              "   0.755133330821991,\n",
              "   0.7635555267333984,\n",
              "   0.7676666378974915,\n",
              "   0.7684666514396667,\n",
              "   0.7762444615364075,\n",
              "   0.7809555530548096,\n",
              "   0.7858889102935791,\n",
              "   0.7847333550453186,\n",
              "   0.7885333299636841,\n",
              "   0.7929111123085022],\n",
              "  [0.3946000039577484,\n",
              "   0.4893999993801117,\n",
              "   0.5063999891281128,\n",
              "   0.5623999834060669,\n",
              "   0.5781999826431274,\n",
              "   0.6313999891281128,\n",
              "   0.6348000168800354,\n",
              "   0.6172000169754028,\n",
              "   0.6226000189781189,\n",
              "   0.6850000023841858,\n",
              "   0.6912000179290771,\n",
              "   0.6959999799728394,\n",
              "   0.7268000245094299,\n",
              "   0.7396000027656555,\n",
              "   0.7301999926567078,\n",
              "   0.7519999742507935,\n",
              "   0.7612000107765198,\n",
              "   0.7423999905586243,\n",
              "   0.7671999931335449,\n",
              "   0.7685999870300293,\n",
              "   0.7868000268936157,\n",
              "   0.7864000201225281,\n",
              "   0.7675999999046326,\n",
              "   0.7778000235557556,\n",
              "   0.7850000262260437,\n",
              "   0.7623999714851379,\n",
              "   0.7868000268936157],\n",
              "  [1.937483310699463,\n",
              "   1.58531653881073,\n",
              "   1.4196879863739014,\n",
              "   1.3049787282943726,\n",
              "   1.2102857828140259,\n",
              "   1.1354233026504517,\n",
              "   1.0747463703155518,\n",
              "   1.0210833549499512,\n",
              "   0.9764711856842041,\n",
              "   0.9308438301086426,\n",
              "   0.8927739858627319,\n",
              "   0.8559013605117798,\n",
              "   0.8254348039627075,\n",
              "   0.790233850479126,\n",
              "   0.7662398219108582,\n",
              "   0.7456926107406616,\n",
              "   0.7220377922058105,\n",
              "   0.7075164318084717,\n",
              "   0.6891474723815918,\n",
              "   0.6753840446472168,\n",
              "   0.6729334592819214,\n",
              "   0.6531671285629272,\n",
              "   0.6405085325241089,\n",
              "   0.6288818717002869,\n",
              "   0.6299118399620056,\n",
              "   0.6173046827316284,\n",
              "   0.6103948354721069],\n",
              "  [1.6429632902145386,\n",
              "   1.411545753479004,\n",
              "   1.388075351715088,\n",
              "   1.2081879377365112,\n",
              "   1.2075976133346558,\n",
              "   1.026553750038147,\n",
              "   1.0533242225646973,\n",
              "   1.1085820198059082,\n",
              "   1.128037929534912,\n",
              "   0.9068713784217834,\n",
              "   0.8806127905845642,\n",
              "   0.8709648251533508,\n",
              "   0.8020491600036621,\n",
              "   0.7636937499046326,\n",
              "   0.7818028330802917,\n",
              "   0.7098261713981628,\n",
              "   0.689300537109375,\n",
              "   0.7432867884635925,\n",
              "   0.677978515625,\n",
              "   0.6758133172988892,\n",
              "   0.6286417245864868,\n",
              "   0.6262099742889404,\n",
              "   0.7142982482910156,\n",
              "   0.7023283839225769,\n",
              "   0.643317461013794,\n",
              "   0.7152656316757202,\n",
              "   0.6267794966697693])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWrOCgprQx7v"
      },
      "source": [
        "### Shift=0.05, Flip=True, rotation=10, patience=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rYqEbEjhQx7z",
        "outputId": "79961c89-6c10-4701-9503-a44fd1a7383e"
      },
      "source": [
        "shift = 0.05\n",
        "horizontal_flip = True\n",
        "rotation = 10\n",
        "workers = 4\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "results_of_model(model, opt[0], opt[1], n=1, plot=True,\n",
        "                 data_augmentation=data_augmentation, \n",
        "                 shift=shift, horizontal_flip=horizontal_flip, rotation=rotation,\n",
        "                 workers=workers, early_stopping=early_stopping)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_CNN_3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,102,858\n",
            "Trainable params: 1,102,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 71s 27ms/step - loss: 2.1015 - accuracy: 0.2029 - val_loss: 1.6472 - val_accuracy: 0.3962\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.6416 - accuracy: 0.3934 - val_loss: 1.4489 - val_accuracy: 0.4682\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.4620 - accuracy: 0.4679 - val_loss: 1.3419 - val_accuracy: 0.5160\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.3267 - accuracy: 0.5223 - val_loss: 1.2043 - val_accuracy: 0.5690\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.2283 - accuracy: 0.5602 - val_loss: 1.2319 - val_accuracy: 0.5744\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.1520 - accuracy: 0.5924 - val_loss: 1.0576 - val_accuracy: 0.6180\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 1.0831 - accuracy: 0.6177 - val_loss: 1.0762 - val_accuracy: 0.6290\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.0409 - accuracy: 0.6334 - val_loss: 1.0282 - val_accuracy: 0.6380\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 37s 27ms/step - loss: 0.9895 - accuracy: 0.6512 - val_loss: 1.1331 - val_accuracy: 0.6240\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.9457 - accuracy: 0.6678 - val_loss: 0.9224 - val_accuracy: 0.6744\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 38s 27ms/step - loss: 0.9105 - accuracy: 0.6816 - val_loss: 0.8638 - val_accuracy: 0.7034\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.8657 - accuracy: 0.7002 - val_loss: 0.8732 - val_accuracy: 0.6946\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.8235 - accuracy: 0.7124 - val_loss: 0.8500 - val_accuracy: 0.7108\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.8053 - accuracy: 0.7197 - val_loss: 0.8077 - val_accuracy: 0.7252\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.7716 - accuracy: 0.7312 - val_loss: 0.7686 - val_accuracy: 0.7396\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.7519 - accuracy: 0.7401 - val_loss: 0.6977 - val_accuracy: 0.7600\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.7292 - accuracy: 0.7467 - val_loss: 0.7096 - val_accuracy: 0.7580\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.7087 - accuracy: 0.7554 - val_loss: 0.7798 - val_accuracy: 0.7306\n",
            "Epoch 19/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6840 - accuracy: 0.7651 - val_loss: 0.6765 - val_accuracy: 0.7694\n",
            "Epoch 20/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6743 - accuracy: 0.7696 - val_loss: 0.6759 - val_accuracy: 0.7742\n",
            "Epoch 21/100\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.6672 - accuracy: 0.7716 - val_loss: 0.6902 - val_accuracy: 0.7652\n",
            "Epoch 22/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6653 - accuracy: 0.7710 - val_loss: 0.6503 - val_accuracy: 0.7782\n",
            "Epoch 23/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6440 - accuracy: 0.7804 - val_loss: 0.7952 - val_accuracy: 0.7472\n",
            "Epoch 24/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6360 - accuracy: 0.7839 - val_loss: 0.7064 - val_accuracy: 0.7612\n",
            "Epoch 25/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6178 - accuracy: 0.7903 - val_loss: 0.6334 - val_accuracy: 0.7840\n",
            "Epoch 26/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6145 - accuracy: 0.7877 - val_loss: 0.7386 - val_accuracy: 0.7648\n",
            "Epoch 27/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.6030 - accuracy: 0.7940 - val_loss: 0.8250 - val_accuracy: 0.7420\n",
            "Epoch 28/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5944 - accuracy: 0.7971 - val_loss: 0.6525 - val_accuracy: 0.7840\n",
            "Epoch 29/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5993 - accuracy: 0.7995 - val_loss: 0.6454 - val_accuracy: 0.7824\n",
            "Epoch 30/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5962 - accuracy: 0.7981 - val_loss: 0.6298 - val_accuracy: 0.7942\n",
            "Epoch 31/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5856 - accuracy: 0.8011 - val_loss: 0.5979 - val_accuracy: 0.7976\n",
            "Epoch 32/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5765 - accuracy: 0.8044 - val_loss: 0.5528 - val_accuracy: 0.8168\n",
            "Epoch 33/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5686 - accuracy: 0.8096 - val_loss: 0.6106 - val_accuracy: 0.7962\n",
            "Epoch 34/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5699 - accuracy: 0.8100 - val_loss: 0.6142 - val_accuracy: 0.7978\n",
            "Epoch 35/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5654 - accuracy: 0.8116 - val_loss: 0.5827 - val_accuracy: 0.8044\n",
            "Epoch 36/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5694 - accuracy: 0.8074 - val_loss: 0.5656 - val_accuracy: 0.8120\n",
            "Epoch 37/100\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.5557 - accuracy: 0.8121 - val_loss: 0.6269 - val_accuracy: 0.7974\n",
            "Epoch 38/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5569 - accuracy: 0.8135 - val_loss: 0.6671 - val_accuracy: 0.7920\n",
            "Epoch 39/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5564 - accuracy: 0.8129 - val_loss: 0.5444 - val_accuracy: 0.8202\n",
            "Epoch 40/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5595 - accuracy: 0.8149 - val_loss: 0.6155 - val_accuracy: 0.8030\n",
            "Epoch 41/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5529 - accuracy: 0.8128 - val_loss: 0.5831 - val_accuracy: 0.8088\n",
            "Epoch 42/100\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.5505 - accuracy: 0.8152 - val_loss: 0.7507 - val_accuracy: 0.7690\n",
            "Epoch 43/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5496 - accuracy: 0.8142 - val_loss: 0.5435 - val_accuracy: 0.8204\n",
            "Epoch 44/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5586 - accuracy: 0.8134 - val_loss: 0.7312 - val_accuracy: 0.7710\n",
            "Epoch 45/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5648 - accuracy: 0.8135 - val_loss: 0.6396 - val_accuracy: 0.7908\n",
            "Epoch 46/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5558 - accuracy: 0.8163 - val_loss: 0.6001 - val_accuracy: 0.7990\n",
            "Epoch 47/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5591 - accuracy: 0.8138 - val_loss: 0.6029 - val_accuracy: 0.8110\n",
            "Epoch 48/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5473 - accuracy: 0.8190 - val_loss: 0.5634 - val_accuracy: 0.8242\n",
            "Epoch 49/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5573 - accuracy: 0.8134 - val_loss: 0.6105 - val_accuracy: 0.8032\n",
            "Epoch 50/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5527 - accuracy: 0.8159 - val_loss: 0.6334 - val_accuracy: 0.8068\n",
            "Epoch 51/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5653 - accuracy: 0.8161 - val_loss: 0.5642 - val_accuracy: 0.8168\n",
            "Epoch 52/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5535 - accuracy: 0.8178 - val_loss: 0.6755 - val_accuracy: 0.7862\n",
            "Epoch 53/100\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.5672 - accuracy: 0.8151 - val_loss: 0.6291 - val_accuracy: 0.8010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([0.27308890223503113,\n",
              "   0.4144666790962219,\n",
              "   0.4851111173629761,\n",
              "   0.5327777862548828,\n",
              "   0.5662888884544373,\n",
              "   0.596666693687439,\n",
              "   0.6206444501876831,\n",
              "   0.6365333199501038,\n",
              "   0.6535999774932861,\n",
              "   0.6709111332893372,\n",
              "   0.6820889115333557,\n",
              "   0.6988666653633118,\n",
              "   0.7112666964530945,\n",
              "   0.7223555445671082,\n",
              "   0.7305333614349365,\n",
              "   0.7407333254814148,\n",
              "   0.7488444447517395,\n",
              "   0.754622220993042,\n",
              "   0.7634000182151794,\n",
              "   0.7696222066879272,\n",
              "   0.7708444595336914,\n",
              "   0.7736222147941589,\n",
              "   0.7793111205101013,\n",
              "   0.7824666500091553,\n",
              "   0.7891555428504944,\n",
              "   0.7886888980865479,\n",
              "   0.7947555780410767,\n",
              "   0.7960222363471985,\n",
              "   0.7993555665016174,\n",
              "   0.8003555536270142,\n",
              "   0.8012222051620483,\n",
              "   0.8026444315910339,\n",
              "   0.8061333298683167,\n",
              "   0.8079777956008911,\n",
              "   0.8087555766105652,\n",
              "   0.8056666851043701,\n",
              "   0.8107555508613586,\n",
              "   0.8110222220420837,\n",
              "   0.8109999895095825,\n",
              "   0.814644455909729,\n",
              "   0.8125110864639282,\n",
              "   0.8154000043869019,\n",
              "   0.814466655254364,\n",
              "   0.8140888810157776,\n",
              "   0.8145111203193665,\n",
              "   0.8148000240325928,\n",
              "   0.8154666423797607,\n",
              "   0.8158000111579895,\n",
              "   0.8157777786254883,\n",
              "   0.8145555257797241,\n",
              "   0.8160222172737122,\n",
              "   0.8163555264472961,\n",
              "   0.813355565071106],\n",
              "  [0.3962000012397766,\n",
              "   0.4681999981403351,\n",
              "   0.515999972820282,\n",
              "   0.5690000057220459,\n",
              "   0.574400007724762,\n",
              "   0.6179999709129333,\n",
              "   0.6290000081062317,\n",
              "   0.6380000114440918,\n",
              "   0.6240000128746033,\n",
              "   0.6743999719619751,\n",
              "   0.7034000158309937,\n",
              "   0.694599986076355,\n",
              "   0.7107999920845032,\n",
              "   0.7251999974250793,\n",
              "   0.7396000027656555,\n",
              "   0.7599999904632568,\n",
              "   0.7580000162124634,\n",
              "   0.7305999994277954,\n",
              "   0.7694000005722046,\n",
              "   0.7742000222206116,\n",
              "   0.7652000188827515,\n",
              "   0.7781999707221985,\n",
              "   0.7472000122070312,\n",
              "   0.7612000107765198,\n",
              "   0.7839999794960022,\n",
              "   0.7648000121116638,\n",
              "   0.7419999837875366,\n",
              "   0.7839999794960022,\n",
              "   0.7824000120162964,\n",
              "   0.7942000031471252,\n",
              "   0.7975999712944031,\n",
              "   0.8167999982833862,\n",
              "   0.7961999773979187,\n",
              "   0.7978000044822693,\n",
              "   0.8044000267982483,\n",
              "   0.8119999766349792,\n",
              "   0.7973999977111816,\n",
              "   0.7919999957084656,\n",
              "   0.8202000260353088,\n",
              "   0.8029999732971191,\n",
              "   0.8087999820709229,\n",
              "   0.7689999938011169,\n",
              "   0.8203999996185303,\n",
              "   0.7710000276565552,\n",
              "   0.7907999753952026,\n",
              "   0.7990000247955322,\n",
              "   0.8109999895095825,\n",
              "   0.8241999745368958,\n",
              "   0.8032000064849854,\n",
              "   0.8068000078201294,\n",
              "   0.8167999982833862,\n",
              "   0.7861999869346619,\n",
              "   0.8009999990463257],\n",
              "  [1.9409650564193726,\n",
              "   1.5911701917648315,\n",
              "   1.4229627847671509,\n",
              "   1.3046985864639282,\n",
              "   1.2116512060165405,\n",
              "   1.1383832693099976,\n",
              "   1.0796318054199219,\n",
              "   1.0273061990737915,\n",
              "   0.9855446815490723,\n",
              "   0.9364495873451233,\n",
              "   0.903404951095581,\n",
              "   0.8605284094810486,\n",
              "   0.8280162215232849,\n",
              "   0.7980394959449768,\n",
              "   0.7732093930244446,\n",
              "   0.7466064095497131,\n",
              "   0.7265415191650391,\n",
              "   0.7103686332702637,\n",
              "   0.6884996294975281,\n",
              "   0.6753048300743103,\n",
              "   0.6680117845535278,\n",
              "   0.6566738486289978,\n",
              "   0.6443336606025696,\n",
              "   0.6376708149909973,\n",
              "   0.6203529834747314,\n",
              "   0.6122623085975647,\n",
              "   0.6065305471420288,\n",
              "   0.602098286151886,\n",
              "   0.5945681929588318,\n",
              "   0.5904184579849243,\n",
              "   0.5855485796928406,\n",
              "   0.5809059739112854,\n",
              "   0.5737040638923645,\n",
              "   0.5735964775085449,\n",
              "   0.571715235710144,\n",
              "   0.5736867785453796,\n",
              "   0.562134325504303,\n",
              "   0.5638558864593506,\n",
              "   0.5626795291900635,\n",
              "   0.5591284036636353,\n",
              "   0.558834433555603,\n",
              "   0.5544474124908447,\n",
              "   0.5564901232719421,\n",
              "   0.5597360134124756,\n",
              "   0.5588368773460388,\n",
              "   0.5612413883209229,\n",
              "   0.5574198961257935,\n",
              "   0.5573394298553467,\n",
              "   0.5592195987701416,\n",
              "   0.5586991310119629,\n",
              "   0.5617476105690002,\n",
              "   0.563352644443512,\n",
              "   0.5678129196166992],\n",
              "  [1.6472036838531494,\n",
              "   1.4489479064941406,\n",
              "   1.3418720960617065,\n",
              "   1.204343557357788,\n",
              "   1.2319015264511108,\n",
              "   1.0575662851333618,\n",
              "   1.0762057304382324,\n",
              "   1.028227686882019,\n",
              "   1.1330899000167847,\n",
              "   0.9224092960357666,\n",
              "   0.8637850880622864,\n",
              "   0.873235821723938,\n",
              "   0.8500309586524963,\n",
              "   0.8077499866485596,\n",
              "   0.768599271774292,\n",
              "   0.6976759433746338,\n",
              "   0.7096450924873352,\n",
              "   0.7798280119895935,\n",
              "   0.6764774918556213,\n",
              "   0.6758618354797363,\n",
              "   0.6901639699935913,\n",
              "   0.6502581834793091,\n",
              "   0.795210599899292,\n",
              "   0.7063532471656799,\n",
              "   0.6333867907524109,\n",
              "   0.7385576367378235,\n",
              "   0.8250142335891724,\n",
              "   0.6525382399559021,\n",
              "   0.6454441547393799,\n",
              "   0.6298121809959412,\n",
              "   0.597936749458313,\n",
              "   0.5527660846710205,\n",
              "   0.6106346845626831,\n",
              "   0.6141753196716309,\n",
              "   0.5827360153198242,\n",
              "   0.5655561685562134,\n",
              "   0.626897394657135,\n",
              "   0.6670976877212524,\n",
              "   0.5443782806396484,\n",
              "   0.6155232191085815,\n",
              "   0.5830565094947815,\n",
              "   0.7506601214408875,\n",
              "   0.5435320138931274,\n",
              "   0.7312350869178772,\n",
              "   0.63963383436203,\n",
              "   0.6001222133636475,\n",
              "   0.6028771996498108,\n",
              "   0.5634469985961914,\n",
              "   0.6105392575263977,\n",
              "   0.6334072947502136,\n",
              "   0.5642251968383789,\n",
              "   0.675485372543335,\n",
              "   0.6291089057922363])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMbYIFCUk05J"
      },
      "source": [
        "### Shift=0.05, Flip=False, patience=5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mnL4J69k05S",
        "outputId": "8844c740-d0a3-4d64-8fcd-451d7dd34714"
      },
      "source": [
        "shift = 0.05\n",
        "horizontal_flip = False\n",
        "rotation = 0\n",
        "workers = 4\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "results_of_model(model, opt[0], opt[1], n=1, plot=True,\n",
        "                 data_augmentation=data_augmentation, \n",
        "                 shift=shift, horizontal_flip=horizontal_flip, rotation=rotation,\n",
        "                 workers=workers, early_stopping=early_stopping)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Bigger_CNN_3ConvBlocks_smaller_padding\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,102,858\n",
            "Trainable params: 1,102,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "Model 0:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1407/1407 [==============================] - 38s 26ms/step - loss: 2.1036 - accuracy: 0.2027 - val_loss: 1.6654 - val_accuracy: 0.3884\n",
            "Epoch 2/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6405 - accuracy: 0.3949 - val_loss: 1.4519 - val_accuracy: 0.4682\n",
            "Epoch 3/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.4539 - accuracy: 0.4705 - val_loss: 1.3279 - val_accuracy: 0.5294\n",
            "Epoch 4/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.3162 - accuracy: 0.5248 - val_loss: 1.1608 - val_accuracy: 0.5808\n",
            "Epoch 5/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.2268 - accuracy: 0.5614 - val_loss: 1.2866 - val_accuracy: 0.5442\n",
            "Epoch 6/100\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 1.1402 - accuracy: 0.5965 - val_loss: 1.0552 - val_accuracy: 0.6328\n",
            "Epoch 7/100\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 1.0697 - accuracy: 0.6216 - val_loss: 1.0404 - val_accuracy: 0.6342\n",
            "Epoch 8/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.0100 - accuracy: 0.6452 - val_loss: 0.9575 - val_accuracy: 0.6628\n",
            "Epoch 9/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.9543 - accuracy: 0.6669 - val_loss: 0.9520 - val_accuracy: 0.6720\n",
            "Epoch 10/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.9071 - accuracy: 0.6820 - val_loss: 0.9264 - val_accuracy: 0.6820\n",
            "Epoch 11/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.8618 - accuracy: 0.6956 - val_loss: 0.8272 - val_accuracy: 0.7158\n",
            "Epoch 12/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.8228 - accuracy: 0.7114 - val_loss: 0.7837 - val_accuracy: 0.7306\n",
            "Epoch 13/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7839 - accuracy: 0.7269 - val_loss: 0.7943 - val_accuracy: 0.7308\n",
            "Epoch 14/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7479 - accuracy: 0.7384 - val_loss: 0.7319 - val_accuracy: 0.7438\n",
            "Epoch 15/100\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 0.7271 - accuracy: 0.7512 - val_loss: 0.8008 - val_accuracy: 0.7280\n",
            "Epoch 16/100\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 0.6937 - accuracy: 0.7597 - val_loss: 0.6772 - val_accuracy: 0.7674\n",
            "Epoch 17/100\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.6801 - accuracy: 0.7646 - val_loss: 0.7361 - val_accuracy: 0.7434\n",
            "Epoch 18/100\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.6569 - accuracy: 0.7747 - val_loss: 0.7238 - val_accuracy: 0.7552\n",
            "Epoch 19/100\n",
            " 170/1407 [==>...........................] - ETA: 31s - loss: 0.6313 - accuracy: 0.7836"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzfT00WDnZ4F"
      },
      "source": [
        "### Shift=0.05, Flip=False, rotation=10, patience=5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1s8qxlMnZ4G"
      },
      "source": [
        "shift = 0.05\n",
        "horizontal_flip = False\n",
        "rotation = 10\n",
        "workers = 4\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "results_of_model(model, opt[0], opt[1], n=1, plot=True,\n",
        "                 data_augmentation=data_augmentation, \n",
        "                 shift=shift, horizontal_flip=horizontal_flip, rotation=rotation,\n",
        "                 workers=workers, early_stopping=early_stopping)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxGHxuDJvfor"
      },
      "source": [
        "# Save model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM-DWrcdcIYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca66275-cd3f-42c2-e810-7531f602949d"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])\n",
        "\n",
        "# make prediction.\n",
        "pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7468 - accuracy: 0.7694\n",
            "Test loss: 0.7468319535255432\n",
            "Test accuracy: 0.7694000005722046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ8WiybqbgzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc7a4b2-be6b-446a-abd4-4ca52633eb1d"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model2.h5'\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model2.h5 \n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.6198 - accuracy: 0.7879\n",
            "Test loss: 0.619803786277771\n",
            "Test accuracy: 0.7878999710083008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhuNgcyIUNMd"
      },
      "source": [
        "y_pred = saved_model.predict_classes(X_test, verbose=0)\n",
        "\n",
        "class_names = ['airplane',\n",
        "                'automobile',\n",
        "                'bird',\n",
        "                'cat',\n",
        "                'deer',\n",
        "                'dog',\n",
        "                'frog',\n",
        "                'horse',\n",
        "                'ship',\n",
        "                'truck']\n",
        "y_pred = [class_names[i] for i in y_pred]\n",
        "\n",
        "submissions=pd.DataFrame({\"id\": list(range(1, len(y_pred)+1)),\n",
        "                          \"label\": y_pred})\n",
        "\n",
        "submissions.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgxobdV6M9AR"
      },
      "source": [
        "# Trained models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVOWJkuKNH1R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}